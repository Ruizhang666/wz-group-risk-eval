#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç‰©äº§ä¸­å¤§å›¾é£æ§ç³»ç»Ÿ - é«˜çº§é—­ç¯ä¼˜ç­›ç³»ç»Ÿ
é‡æ–°è®¾è®¡ç‰ˆ - æ»¡è¶³æ‰€æœ‰æ–°éœ€æ±‚

æ–°åŠŸèƒ½ï¼š
1. æ—¶é—´ç»´åº¦åˆ†æ - ä¸Šä¸‹æ¸¸äº¤æ˜“æ—¶é—´é—´éš”æ§åˆ¶
2. è‚¡æƒåˆ†æé›†æˆ - è°ƒç”¨loop_filter_scriptåˆ†æ
3. å®Œæ•´æ€§æ£€æŸ¥ - Sanity Checkç¡®ä¿æ•°æ®å®Œæ•´
4. è‡ªåŠ¨æ•°æ®è¯»å– - æ™ºèƒ½å‘ç°å¹¶åŠ è½½æ‰€æœ‰ç›¸å…³æ•°æ®
5. çœŸå®æ•°æ®å¯¼å‘ - ä¸ä½¿ç”¨ä¼°ç®—å€¼
6. ç¯è·¯ç±»å‹æ§åˆ¶ - å¯é€‰æ‹©ç‰¹å®šç±»å‹ç¯è·¯
"""

import tkinter as tk
from tkinter import ttk, messagebox, scrolledtext
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
from matplotlib.figure import Figure
import pandas as pd
import numpy as np
import os
import re
import json
import subprocess
import networkx as nx
from datetime import datetime, timedelta
from collections import defaultdict, Counter
import threading
import queue
import warnings
warnings.filterwarnings('ignore')

# é…ç½®ä¸­æ–‡å­—ä½“
try:
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']
    plt.rcParams['axes.unicode_minus'] = False
except:
    pass

class AdvancedLoopFilterGUI:
    def __init__(self, root):
        self.root = root
        self.root.title("ç‰©äº§ä¸­å¤§å›¾é£æ§ç³»ç»Ÿ - é«˜çº§é—­ç¯ä¼˜ç­›ç³»ç»Ÿ v2.0")
        self.root.geometry("1600x1000")
        
        # å°è¯•æœ€å¤§åŒ–çª—å£
        try:
            self.root.state('zoomed')
        except:
            try:
                self.root.attributes('-zoomed', True)
            except:
                pass
        
        # æ•°æ®å­˜å‚¨
        self.raw_loops_data = {}           # åŸå§‹ç¯è·¯æ•°æ®
        self.loop_metrics_data = {}        # ç¯è·¯æŒ‡æ ‡æ•°æ®
        self.graph_data = None             # å›¾æ•°æ®
        self.filtered_results = pd.DataFrame()  # ç­›é€‰ç»“æœ
        self.data_sources = {}             # æ•°æ®æºä¿¡æ¯
        
        # ç­›é€‰å‚æ•°
        self.filter_params = {
            # æ—¶é—´ç»´åº¦å‚æ•°
            'time_window_months': tk.IntVar(value=12),
            'max_time_gap_days': tk.IntVar(value=30),
            'min_upstream_transactions': tk.IntVar(value=1),
            'min_downstream_transactions': tk.IntVar(value=1),
            
            # äº¤æ˜“é‡‘é¢å‚æ•°
            'min_total_amount': tk.DoubleVar(value=0),
            'min_upstream_amount': tk.DoubleVar(value=0),
            'min_downstream_amount': tk.DoubleVar(value=0),
            
            # è‚¡æƒå‚æ•°
            'min_equity_ratio': tk.DoubleVar(value=0),
            'max_equity_ratio': tk.DoubleVar(value=100),
            'min_shareholders': tk.IntVar(value=1),
            
            # ç¯è·¯ç»“æ„å‚æ•°
            'min_nodes': tk.IntVar(value=3),
            'max_nodes': tk.IntVar(value=15),
            'selected_loop_types': [],
            
            # è¾“å‡ºæ§åˆ¶
            'max_results': tk.IntVar(value=1000)
        }
        
        # GUIç»„ä»¶
        self.progress_queue = queue.Queue()
        self.log_queue = queue.Queue()
        
        # åˆ›å»ºç•Œé¢
        self.create_widgets()
        
        # ç»‘å®šå‚æ•°å˜åŒ–äº‹ä»¶
        self.bind_parameter_events()
        
        # è‡ªåŠ¨åŠ è½½æ•°æ®
        self.auto_load_data()
    
    def create_widgets(self):
        """åˆ›å»ºä¸»ç•Œé¢ç»„ä»¶"""
        # åˆ›å»ºä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # é¡¶éƒ¨æ§åˆ¶é¢æ¿
        self.create_control_panel(main_frame)
        
        # ä¸»å†…å®¹åŒºåŸŸ - ä½¿ç”¨PanedWindowåˆ†å‰²
        paned = ttk.PanedWindow(main_frame, orient=tk.HORIZONTAL)
        paned.pack(fill=tk.BOTH, expand=True, pady=(10, 0))
        
        # å·¦ä¾§é¢æ¿
        left_frame = ttk.Frame(paned)
        paned.add(left_frame, weight=1)
        
        # å³ä¾§é¢æ¿
        right_frame = ttk.Frame(paned)
        paned.add(right_frame, weight=2)
        
        # åˆ›å»ºå·¦å³é¢æ¿å†…å®¹
        self.create_left_panel(left_frame)
        self.create_right_panel(right_frame)
        
        # åº•éƒ¨çŠ¶æ€æ 
        self.create_status_panel(main_frame)
    
    def create_control_panel(self, parent):
        """åˆ›å»ºé¡¶éƒ¨æ§åˆ¶é¢æ¿"""
        control_frame = ttk.LabelFrame(parent, text="ç³»ç»Ÿæ§åˆ¶")
        control_frame.pack(fill=tk.X, pady=(0, 10))
        
        # æ•°æ®æ§åˆ¶åŒº
        data_frame = ttk.Frame(control_frame)
        data_frame.pack(side=tk.LEFT, padx=5, pady=5)
        
        ttk.Button(data_frame, text="ğŸ”„ é‡æ–°åŠ è½½æ•°æ®", 
                  command=self.reload_all_data).pack(side=tk.LEFT, padx=2)
        
        ttk.Button(data_frame, text="ğŸ” å®Œæ•´æ€§æ£€æŸ¥", 
                  command=self.run_sanity_check).pack(side=tk.LEFT, padx=2)
        
        ttk.Button(data_frame, text="ğŸ“Š è¿è¡Œè‚¡æƒåˆ†æ", 
                  command=self.run_equity_analysis).pack(side=tk.LEFT, padx=2)
        
        # ç­›é€‰æ§åˆ¶åŒº
        filter_frame = ttk.Frame(control_frame)
        filter_frame.pack(side=tk.LEFT, padx=(20, 5), pady=5)
        
        ttk.Button(filter_frame, text="ğŸ¯ æ‰§è¡Œç­›é€‰", 
                  command=self.execute_filtering).pack(side=tk.LEFT, padx=2)
        
        ttk.Button(filter_frame, text="ğŸ”„ é‡ç½®å‚æ•°", 
                  command=self.reset_parameters).pack(side=tk.LEFT, padx=2)
        
        # å¯¼å‡ºæ§åˆ¶åŒº
        export_frame = ttk.Frame(control_frame)
        export_frame.pack(side=tk.RIGHT, padx=5, pady=5)
        
        ttk.Button(export_frame, text="ğŸ“¤ å¯¼å‡ºç»“æœ", 
                  command=self.export_results).pack(side=tk.LEFT, padx=2)
        
        ttk.Button(export_frame, text="ğŸ“‹ ç”ŸæˆæŠ¥å‘Š", 
                  command=self.generate_report).pack(side=tk.LEFT, padx=2)
    
    def create_left_panel(self, parent):
        """åˆ›å»ºå·¦ä¾§æ§åˆ¶é¢æ¿"""
        # æ•°æ®æºä¿¡æ¯
        self.create_data_source_panel(parent)
        
        # ç­›é€‰å‚æ•°é¢æ¿
        self.create_filter_parameters_panel(parent)
        
        # ç¯è·¯ç±»å‹é€‰æ‹©
        self.create_loop_type_panel(parent)
    
    def create_data_source_panel(self, parent):
        """åˆ›å»ºæ•°æ®æºä¿¡æ¯é¢æ¿"""
        data_frame = ttk.LabelFrame(parent, text="æ•°æ®æºä¿¡æ¯")
        data_frame.pack(fill=tk.X, padx=5, pady=5)
        
        # æ•°æ®æºåˆ—è¡¨
        self.data_tree = ttk.Treeview(data_frame, 
                                     columns=('çŠ¶æ€', 'è®°å½•æ•°', 'æœ€åæ›´æ–°', 'å¤§å°'), 
                                     show='tree headings', height=6)
        
        self.data_tree.heading('#0', text='æ•°æ®æº')
        self.data_tree.heading('çŠ¶æ€', text='çŠ¶æ€')
        self.data_tree.heading('è®°å½•æ•°', text='è®°å½•æ•°')
        self.data_tree.heading('æœ€åæ›´æ–°', text='æœ€åæ›´æ–°')
        self.data_tree.heading('å¤§å°', text='å¤§å°')
        
        self.data_tree.column('#0', width=150)
        self.data_tree.column('çŠ¶æ€', width=60)
        self.data_tree.column('è®°å½•æ•°', width=80)
        self.data_tree.column('æœ€åæ›´æ–°', width=100)
        self.data_tree.column('å¤§å°', width=50)
        
        self.data_tree.pack(fill=tk.X, padx=5, pady=5)
    
    def create_filter_parameters_panel(self, parent):
        """åˆ›å»ºç­›é€‰å‚æ•°é¢æ¿"""
        param_frame = ttk.LabelFrame(parent, text="ç­›é€‰å‚æ•°")
        param_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # åˆ›å»ºæ»šåŠ¨åŒºåŸŸ
        canvas = tk.Canvas(param_frame)
        scrollbar = ttk.Scrollbar(param_frame, orient="vertical", command=canvas.yview)
        scrollable_frame = ttk.Frame(canvas)
        
        scrollable_frame.bind("<Configure>", 
                             lambda e: canvas.configure(scrollregion=canvas.bbox("all")))
        
        canvas.create_window((0, 0), window=scrollable_frame, anchor="nw")
        canvas.configure(yscrollcommand=scrollbar.set)
        
        canvas.pack(side="left", fill="both", expand=True)
        scrollbar.pack(side="right", fill="y")
        
        # æ—¶é—´ç»´åº¦å‚æ•°
        self.create_time_parameters(scrollable_frame)
        
        # äº¤æ˜“é‡‘é¢å‚æ•°
        self.create_amount_parameters(scrollable_frame)
        
        # è‚¡æƒå‚æ•°
        self.create_equity_parameters(scrollable_frame)
        
        # ç»“æ„å‚æ•°
        self.create_structure_parameters(scrollable_frame)
    
    def create_time_parameters(self, parent):
        """åˆ›å»ºæ—¶é—´ç»´åº¦å‚æ•°"""
        frame = ttk.LabelFrame(parent, text="â° æ—¶é—´ç»´åº¦åˆ†æ")
        frame.pack(fill=tk.X, padx=5, pady=5)
        
        # æ—¶é—´çª—å£
        ttk.Label(frame, text="åˆ†ææ—¶é—´çª—å£ (æœˆ):").pack(anchor=tk.W, padx=5, pady=2)
        time_window_frame = ttk.Frame(frame)
        time_window_frame.pack(fill=tk.X, padx=5, pady=2)
        
        time_window_scale = ttk.Scale(time_window_frame, from_=1, to=36,
                                     variable=self.filter_params['time_window_months'],
                                     orient=tk.HORIZONTAL)
        time_window_scale.pack(side=tk.LEFT, fill=tk.X, expand=True)
        
        self.time_window_label = ttk.Label(time_window_frame, text="12ä¸ªæœˆ")
        self.time_window_label.pack(side=tk.RIGHT, padx=(5, 0))
        
        # ä¸Šä¸‹æ¸¸äº¤æ˜“æ—¶é—´é—´éš”
        ttk.Label(frame, text="æœ€å¤§äº¤æ˜“æ—¶é—´é—´éš” (å¤©):").pack(anchor=tk.W, padx=5, pady=2)
        time_gap_frame = ttk.Frame(frame)
        time_gap_frame.pack(fill=tk.X, padx=5, pady=2)
        
        time_gap_scale = ttk.Scale(time_gap_frame, from_=1, to=365,
                                  variable=self.filter_params['max_time_gap_days'],
                                  orient=tk.HORIZONTAL)
        time_gap_scale.pack(side=tk.LEFT, fill=tk.X, expand=True)
        
        self.time_gap_label = ttk.Label(time_gap_frame, text="30å¤©")
        self.time_gap_label.pack(side=tk.RIGHT, padx=(5, 0))
        
        # æœ€å°äº¤æ˜“æ¬¡æ•°
        min_trans_frame = ttk.Frame(frame)
        min_trans_frame.pack(fill=tk.X, padx=5, pady=2)
        
        ttk.Label(min_trans_frame, text="æœ€å°ä¸Šæ¸¸äº¤æ˜“æ¬¡æ•°:").pack(side=tk.LEFT)
        upstream_spin = ttk.Spinbox(min_trans_frame, from_=0, to=20, width=5,
                                   textvariable=self.filter_params['min_upstream_transactions'])
        upstream_spin.pack(side=tk.RIGHT)
        
        min_trans_frame2 = ttk.Frame(frame)
        min_trans_frame2.pack(fill=tk.X, padx=5, pady=2)
        
        ttk.Label(min_trans_frame2, text="æœ€å°ä¸‹æ¸¸äº¤æ˜“æ¬¡æ•°:").pack(side=tk.LEFT)
        downstream_spin = ttk.Spinbox(min_trans_frame2, from_=0, to=20, width=5,
                                     textvariable=self.filter_params['min_downstream_transactions'])
        downstream_spin.pack(side=tk.RIGHT)
    
    def create_amount_parameters(self, parent):
        """åˆ›å»ºäº¤æ˜“é‡‘é¢å‚æ•°"""
        frame = ttk.LabelFrame(parent, text="ğŸ’° äº¤æ˜“é‡‘é¢åˆ†æ")
        frame.pack(fill=tk.X, padx=5, pady=5)
        
        # æ€»äº¤æ˜“é‡‘é¢
        ttk.Label(frame, text="æœ€å°æ€»äº¤æ˜“é‡‘é¢ (ä¸‡å…ƒ):").pack(anchor=tk.W, padx=5, pady=2)
        total_amount_frame = ttk.Frame(frame)
        total_amount_frame.pack(fill=tk.X, padx=5, pady=2)
        
        total_amount_scale = ttk.Scale(total_amount_frame, from_=0, to=10000,
                                     variable=self.filter_params['min_total_amount'],
                                     orient=tk.HORIZONTAL)
        total_amount_scale.pack(side=tk.LEFT, fill=tk.X, expand=True)
        
        self.total_amount_label = ttk.Label(total_amount_frame, text="0ä¸‡")
        self.total_amount_label.pack(side=tk.RIGHT, padx=(5, 0))
        
        # ä¸Šæ¸¸äº¤æ˜“é‡‘é¢
        ttk.Label(frame, text="æœ€å°ä¸Šæ¸¸äº¤æ˜“é‡‘é¢ (ä¸‡å…ƒ):").pack(anchor=tk.W, padx=5, pady=2)
        upstream_amount_frame = ttk.Frame(frame)
        upstream_amount_frame.pack(fill=tk.X, padx=5, pady=2)
        
        upstream_amount_scale = ttk.Scale(upstream_amount_frame, from_=0, to=5000,
                                        variable=self.filter_params['min_upstream_amount'],
                                        orient=tk.HORIZONTAL)
        upstream_amount_scale.pack(side=tk.LEFT, fill=tk.X, expand=True)
        
        self.upstream_amount_label = ttk.Label(upstream_amount_frame, text="0ä¸‡")
        self.upstream_amount_label.pack(side=tk.RIGHT, padx=(5, 0))
        
        # ä¸‹æ¸¸äº¤æ˜“é‡‘é¢
        ttk.Label(frame, text="æœ€å°ä¸‹æ¸¸äº¤æ˜“é‡‘é¢ (ä¸‡å…ƒ):").pack(anchor=tk.W, padx=5, pady=2)
        downstream_amount_frame = ttk.Frame(frame)
        downstream_amount_frame.pack(fill=tk.X, padx=5, pady=2)
        
        downstream_amount_scale = ttk.Scale(downstream_amount_frame, from_=0, to=5000,
                                          variable=self.filter_params['min_downstream_amount'],
                                          orient=tk.HORIZONTAL)
        downstream_amount_scale.pack(side=tk.LEFT, fill=tk.X, expand=True)
        
        self.downstream_amount_label = ttk.Label(downstream_amount_frame, text="0ä¸‡")
        self.downstream_amount_label.pack(side=tk.RIGHT, padx=(5, 0))
    
    def create_equity_parameters(self, parent):
        """åˆ›å»ºè‚¡æƒå‚æ•°"""
        frame = ttk.LabelFrame(parent, text="ğŸ›ï¸ è‚¡æƒç»“æ„åˆ†æ")
        frame.pack(fill=tk.X, padx=5, pady=5)
        
        # è‚¡æƒæ¯”ä¾‹èŒƒå›´
        ttk.Label(frame, text="è‚¡æƒæ¯”ä¾‹èŒƒå›´ (%):").pack(anchor=tk.W, padx=5, pady=2)
        
        equity_range_frame = ttk.Frame(frame)
        equity_range_frame.pack(fill=tk.X, padx=5, pady=2)
        
        ttk.Label(equity_range_frame, text="æœ€å°:").pack(side=tk.LEFT)
        min_equity_spin = ttk.Spinbox(equity_range_frame, from_=0, to=100, width=6,
                                     textvariable=self.filter_params['min_equity_ratio'])
        min_equity_spin.pack(side=tk.LEFT, padx=(5, 10))
        
        ttk.Label(equity_range_frame, text="æœ€å¤§:").pack(side=tk.LEFT)
        max_equity_spin = ttk.Spinbox(equity_range_frame, from_=0, to=100, width=6,
                                     textvariable=self.filter_params['max_equity_ratio'])
        max_equity_spin.pack(side=tk.LEFT, padx=5)
        
        # æœ€å°è‚¡ä¸œæ•°
        min_shareholders_frame = ttk.Frame(frame)
        min_shareholders_frame.pack(fill=tk.X, padx=5, pady=2)
        
        ttk.Label(min_shareholders_frame, text="æœ€å°è‚¡ä¸œæ•°:").pack(side=tk.LEFT)
        shareholders_spin = ttk.Spinbox(min_shareholders_frame, from_=1, to=50, width=5,
                                      textvariable=self.filter_params['min_shareholders'])
        shareholders_spin.pack(side=tk.RIGHT)
    
    def create_structure_parameters(self, parent):
        """åˆ›å»ºç»“æ„å‚æ•°"""
        frame = ttk.LabelFrame(parent, text="ğŸ”— ç¯è·¯ç»“æ„å‚æ•°")
        frame.pack(fill=tk.X, padx=5, pady=5)
        
        # èŠ‚ç‚¹æ•°èŒƒå›´
        ttk.Label(frame, text="ç¯è·¯èŠ‚ç‚¹æ•°èŒƒå›´:").pack(anchor=tk.W, padx=5, pady=2)
        
        nodes_range_frame = ttk.Frame(frame)
        nodes_range_frame.pack(fill=tk.X, padx=5, pady=2)
        
        ttk.Label(nodes_range_frame, text="æœ€å°:").pack(side=tk.LEFT)
        min_nodes_spin = ttk.Spinbox(nodes_range_frame, from_=3, to=20, width=4,
                                    textvariable=self.filter_params['min_nodes'])
        min_nodes_spin.pack(side=tk.LEFT, padx=(5, 10))
        
        ttk.Label(nodes_range_frame, text="æœ€å¤§:").pack(side=tk.LEFT)
        max_nodes_spin = ttk.Spinbox(nodes_range_frame, from_=3, to=20, width=4,
                                    textvariable=self.filter_params['max_nodes'])
        max_nodes_spin.pack(side=tk.LEFT, padx=5)
        
        # æœ€å¤§ç»“æœæ•°
        max_results_frame = ttk.Frame(frame)
        max_results_frame.pack(fill=tk.X, padx=5, pady=2)
        
        ttk.Label(max_results_frame, text="æœ€å¤§è¾“å‡ºç»“æœæ•°:").pack(side=tk.LEFT)
        results_spin = ttk.Spinbox(max_results_frame, from_=10, to=10000, width=6,
                                  textvariable=self.filter_params['max_results'])
        results_spin.pack(side=tk.RIGHT)
    
    def create_loop_type_panel(self, parent):
        """åˆ›å»ºç¯è·¯ç±»å‹é€‰æ‹©é¢æ¿"""
        frame = ttk.LabelFrame(parent, text="ğŸ¯ ç¯è·¯ç±»å‹é€‰æ‹©")
        frame.pack(fill=tk.X, padx=5, pady=5)
        
        # ç¯è·¯ç±»å‹å¤é€‰æ¡†åˆ—è¡¨
        self.loop_type_frame = ttk.Frame(frame)
        self.loop_type_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # åˆå§‹åŒ–æ—¶ä¼šå¡«å……å¯ç”¨çš„ç¯è·¯ç±»å‹
        self.loop_type_vars = {}
    
    def create_right_panel(self, parent):
        """åˆ›å»ºå³ä¾§é¢æ¿"""
        # åˆ›å»ºé€‰é¡¹å¡
        self.notebook = ttk.Notebook(parent)
        self.notebook.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # åˆ›å»ºå„ä¸ªé€‰é¡¹å¡
        self.create_overview_tab()
        self.create_time_analysis_tab()
        self.create_equity_analysis_tab()
        self.create_results_tab()
        self.create_log_tab()
    
    def create_overview_tab(self):
        """åˆ›å»ºæ¦‚è§ˆé€‰é¡¹å¡"""
        overview_frame = ttk.Frame(self.notebook)
        self.notebook.add(overview_frame, text="ğŸ“Š æ•°æ®æ¦‚è§ˆ")
        
        # ç»Ÿè®¡ä¿¡æ¯æ˜¾ç¤º
        stats_frame = ttk.LabelFrame(overview_frame, text="æ•°æ®ç»Ÿè®¡")
        stats_frame.pack(fill=tk.X, padx=10, pady=10)
        
        self.stats_text = scrolledtext.ScrolledText(stats_frame, height=15, width=80)
        self.stats_text.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
    
    def create_time_analysis_tab(self):
        """åˆ›å»ºæ—¶é—´åˆ†æé€‰é¡¹å¡"""
        time_frame = ttk.Frame(self.notebook)
        self.notebook.add(time_frame, text="â° æ—¶é—´åˆ†æ")
        
        # æ—¶é—´åˆ†æå›¾è¡¨
        self.time_fig = Figure(dpi=80)
        self.time_canvas = FigureCanvasTkAgg(self.time_fig, time_frame)
        self.time_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
    
    def create_equity_analysis_tab(self):
        """åˆ›å»ºè‚¡æƒåˆ†æé€‰é¡¹å¡"""
        equity_frame = ttk.Frame(self.notebook)
        self.notebook.add(equity_frame, text="ğŸ›ï¸ è‚¡æƒåˆ†æ")
        
        # è‚¡æƒåˆ†æå›¾è¡¨
        self.equity_fig = Figure(dpi=80)
        self.equity_canvas = FigureCanvasTkAgg(self.equity_fig, equity_frame)
        self.equity_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
    
    def create_results_tab(self):
        """åˆ›å»ºç»“æœé€‰é¡¹å¡"""
        results_frame = ttk.Frame(self.notebook)
        self.notebook.add(results_frame, text="ğŸ¯ ç­›é€‰ç»“æœ")
        
        # ç»“æœè¡¨æ ¼
        columns = ['ç¯è·¯ID', 'ç±»å‹', 'èŠ‚ç‚¹æ•°', 'ä¸Šæ¸¸äº¤æ˜“é‡‘é¢', 'ä¸‹æ¸¸äº¤æ˜“é‡‘é¢', 
                  'æ—¶é—´é—´éš”', 'è‚¡æƒé›†ä¸­åº¦', 'æœ€åäº¤æ˜“æ—¶é—´']
        
        self.results_tree = ttk.Treeview(results_frame, columns=columns, 
                                        show='headings', height=20)
        
        for col in columns:
            self.results_tree.heading(col, text=col)
            self.results_tree.column(col, width=100)
        
        # æ·»åŠ æ»šåŠ¨æ¡
        results_scrollbar = ttk.Scrollbar(results_frame, orient="vertical", 
                                        command=self.results_tree.yview)
        self.results_tree.configure(yscrollcommand=results_scrollbar.set)
        
        self.results_tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        results_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
    
    def create_log_tab(self):
        """åˆ›å»ºæ—¥å¿—é€‰é¡¹å¡"""
        log_frame = ttk.Frame(self.notebook)
        self.notebook.add(log_frame, text="ğŸ“ ç³»ç»Ÿæ—¥å¿—")
        
        # æ—¥å¿—æ˜¾ç¤ºåŒºåŸŸ
        self.log_text = scrolledtext.ScrolledText(log_frame, height=25, width=100,
                                                 font=('Consolas', 9))
        self.log_text.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
    
    def create_status_panel(self, parent):
        """åˆ›å»ºçŠ¶æ€é¢æ¿"""
        status_frame = ttk.LabelFrame(parent, text="ç³»ç»ŸçŠ¶æ€")
        status_frame.pack(fill=tk.X, pady=(10, 0))
        
        # çŠ¶æ€ä¿¡æ¯
        status_info_frame = ttk.Frame(status_frame)
        status_info_frame.pack(fill=tk.X, padx=5, pady=5)
        
        self.status_var = tk.StringVar(value="ç³»ç»Ÿå°±ç»ª - ç­‰å¾…æ•°æ®åŠ è½½")
        ttk.Label(status_info_frame, textvariable=self.status_var).pack(side=tk.LEFT)
        
        # è¿›åº¦æ¡
        self.progress_var = tk.DoubleVar()
        self.progress_bar = ttk.Progressbar(status_info_frame, 
                                          variable=self.progress_var,
                                          maximum=100)
        self.progress_bar.pack(side=tk.RIGHT, fill=tk.X, expand=True, padx=(10, 0))
    
    def bind_parameter_events(self):
        """ç»‘å®šå‚æ•°å˜åŒ–äº‹ä»¶"""
        for param_name, param_var in self.filter_params.items():
            if isinstance(param_var, (tk.IntVar, tk.DoubleVar)):
                param_var.trace('w', self.on_parameter_change)
    
    def on_parameter_change(self, *args):
        """å‚æ•°å˜åŒ–æ—¶çš„å›è°ƒ"""
        self.update_parameter_labels()
        
        # å¦‚æœæœ‰æ•°æ®ï¼Œè‡ªåŠ¨æ›´æ–°é¢„è§ˆ
        if hasattr(self, 'raw_loops_data') and self.raw_loops_data:
            self.update_filter_preview()
    
    def update_parameter_labels(self):
        """æ›´æ–°å‚æ•°æ ‡ç­¾æ˜¾ç¤º"""
        if hasattr(self, 'time_window_label'):
            self.time_window_label.config(
                text=f"{self.filter_params['time_window_months'].get()}ä¸ªæœˆ")
        
        if hasattr(self, 'time_gap_label'):
            self.time_gap_label.config(
                text=f"{self.filter_params['max_time_gap_days'].get()}å¤©")
        
        if hasattr(self, 'total_amount_label'):
            self.total_amount_label.config(
                text=f"{self.filter_params['min_total_amount'].get():.0f}ä¸‡")
        
        if hasattr(self, 'upstream_amount_label'):
            self.upstream_amount_label.config(
                text=f"{self.filter_params['min_upstream_amount'].get():.0f}ä¸‡")
        
        if hasattr(self, 'downstream_amount_label'):
            self.downstream_amount_label.config(
                text=f"{self.filter_params['min_downstream_amount'].get():.0f}ä¸‡")
    
    def auto_load_data(self):
        """è‡ªåŠ¨åŠ è½½æ‰€æœ‰å¯ç”¨æ•°æ®"""
        self.log("ğŸš€ å¼€å§‹è‡ªåŠ¨æ‰«æå’ŒåŠ è½½æ•°æ®...")
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œæ•°æ®åŠ è½½
        threading.Thread(target=self._auto_load_data_worker, daemon=True).start()
        
        # å¯åŠ¨UIæ›´æ–°
        self.root.after(100, self.update_ui_from_queues)
    
    def _auto_load_data_worker(self):
        """æ•°æ®åŠ è½½å·¥ä½œçº¿ç¨‹"""
        try:
            # æ‰«æå¯ç”¨çš„æ•°æ®æ–‡ä»¶
            data_files = self.scan_data_files()
            
            total_files = len(data_files)
            loaded_files = 0
            
            for file_type, file_info in data_files.items():
                self.progress_queue.put(('progress', loaded_files / total_files * 100))
                self.log_queue.put(f"ğŸ“‚ åŠ è½½ {file_type}: {file_info['path']}")
                
                try:
                    if file_type == 'loops':
                        self.raw_loops_data = self.load_loops_data(file_info['path'])
                        self.data_sources['loops'] = file_info
                        
                    elif file_type == 'metrics':
                        self.loop_metrics_data = self.load_metrics_data(file_info['path'])
                        self.data_sources['metrics'] = file_info
                        
                    elif file_type == 'graph':
                        self.graph_data = self.load_graph_data(file_info['path'])
                        self.data_sources['graph'] = file_info
                    
                    file_info['status'] = 'âœ… å·²åŠ è½½'
                    file_info['records'] = self.get_record_count(file_type)
                    
                except Exception as e:
                    file_info['status'] = f'âŒ å¤±è´¥: {str(e)[:20]}'
                    self.log_queue.put(f"âŒ åŠ è½½å¤±è´¥ {file_type}: {str(e)}")
                
                loaded_files += 1
            
            # å®Œæˆæ•°æ®åŠ è½½åçš„å¤„ç†
            self.progress_queue.put(('progress', 100))
            self.log_queue.put("âœ… æ•°æ®åŠ è½½å®Œæˆ")
            
            # æ›´æ–°UIç»„ä»¶
            self.progress_queue.put(('update_data_tree', None))
            self.progress_queue.put(('update_loop_types', None))
            self.progress_queue.put(('update_overview', None))
            
        except Exception as e:
            self.log_queue.put(f"âŒ æ•°æ®åŠ è½½è¿‡ç¨‹å‡ºé”™: {str(e)}")
    
    def scan_data_files(self):
        """ç®€åŒ–ç‰ˆï¼šæ‰«æå¯ç”¨çš„æ•°æ®æ–‡ä»¶ï¼Œä¼˜å…ˆé€‰æ‹©ç‰¹å®šæ–‡ä»¶ã€‚"""
        self.log("ğŸ¤– (æ–°) å¼€å§‹æ‰«ææ•°æ®æ–‡ä»¶ (scan_data_files)...")
        data_files = {}
        
        # ç¯è·¯æ•°æ® - ä¼˜å…ˆé€‰æ‹©ä¼˜åŒ–ç‰ˆæœ¬ï¼Œç„¶åæ˜¯nxç‰ˆæœ¬
        loop_file_paths = [
            ('outputs/loop_results/equity_loops_optimized.txt', 'igraph'),
            ('outputs/loop_results/equity_loops_nx.txt', 'networkx')
        ]
        
        for path, engine_type in loop_file_paths:
            self.log(f"æ£€æŸ¥ç¯è·¯æ–‡ä»¶: {path}")
            if os.path.exists(path):
                data_files['loops'] = {
                    'path': path,
                    'size': os.path.getsize(path),
                    'modified': datetime.fromtimestamp(os.path.getmtime(path)),
                    'status': 'â³ å¾…åŠ è½½',
                    'engine': engine_type 
                }
                self.log(f"ğŸ“ é€‰æ‹©ç¯è·¯æ•°æ®æ–‡ä»¶: {path} (å¼•æ“: {engine_type})")
                break
            else:
                self.log(f"ç¯è·¯æ–‡ä»¶æœªæ‰¾åˆ°: {path}")

        if 'loops' not in data_files:
            self.log("âš ï¸ æœªæ‰¾åˆ°æŒ‡å®šçš„ç¯è·¯æ•°æ®æ–‡ä»¶ã€‚")

        # æŒ‡æ ‡æ•°æ®
        metrics_file_path = 'outputs/loop_analysis/loop_metrics.csv'
        self.log(f"æ£€æŸ¥æŒ‡æ ‡æ–‡ä»¶: {metrics_file_path}")
        if os.path.exists(metrics_file_path):
            data_files['metrics'] = {
                'path': metrics_file_path,
                'size': os.path.getsize(metrics_file_path),
                'modified': datetime.fromtimestamp(os.path.getmtime(metrics_file_path)),
                'status': 'â³ å¾…åŠ è½½'
                # 'engine': 'pandas' #  å¦‚æœéœ€è¦ï¼Œå¯ä»¥ä¸ºå…¶ä»–ç±»å‹æ–‡ä»¶ä¹Ÿæ·»åŠ  engine
            }
            self.log(f"ğŸ“Š é€‰æ‹©æŒ‡æ ‡æ•°æ®æ–‡ä»¶: {metrics_file_path}")
        else:
            self.log(f"æŒ‡æ ‡æ–‡ä»¶æœªæ‰¾åˆ°: {metrics_file_path}")
            # å¯ä»¥è€ƒè™‘å¤‡ç”¨è·¯å¾„ï¼Œä¾‹å¦‚ loop_basic_info.csv
            backup_metrics_path = 'outputs/loop_analysis/loop_basic_info.csv'
            self.log(f"æ£€æŸ¥å¤‡ç”¨æŒ‡æ ‡æ–‡ä»¶: {backup_metrics_path}")
            if os.path.exists(backup_metrics_path):
                data_files['metrics'] = {
                    'path': backup_metrics_path,
                    'size': os.path.getsize(backup_metrics_path),
                    'modified': datetime.fromtimestamp(os.path.getmtime(backup_metrics_path)),
                    'status': 'â³ å¾…åŠ è½½'
                }
                self.log(f"ğŸ“Š é€‰æ‹©å¤‡ç”¨æŒ‡æ ‡æ•°æ®æ–‡ä»¶: {backup_metrics_path}")
            else:
                self.log(f"å¤‡ç”¨æŒ‡æ ‡æ–‡ä»¶æœªæ‰¾åˆ°: {backup_metrics_path}")


        # å›¾æ•°æ®
        graph_file_path = 'model/final_heterogeneous_graph.graphml'
        self.log(f"æ£€æŸ¥å›¾æ•°æ®æ–‡ä»¶: {graph_file_path}")
        if os.path.exists(graph_file_path):
            data_files['graph'] = {
                'path': graph_file_path,
                'size': os.path.getsize(graph_file_path),
                'modified': datetime.fromtimestamp(os.path.getmtime(graph_file_path)),
                'status': 'â³ å¾…åŠ è½½'
                # 'engine': 'networkx'
            }
            self.log(f"ğŸ“ˆ é€‰æ‹©å›¾æ•°æ®æ–‡ä»¶: {graph_file_path}")
        else:
            self.log(f"å›¾æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {graph_file_path}")
            # å¯ä»¥è€ƒè™‘å¤‡ç”¨è·¯å¾„
            backup_graph_path = 'model/simplified_loop_detection_graph.graphml'
            self.log(f"æ£€æŸ¥å¤‡ç”¨å›¾æ•°æ®æ–‡ä»¶: {backup_graph_path}")
            if os.path.exists(backup_graph_path):
                data_files['graph'] = {
                    'path': backup_graph_path,
                    'size': os.path.getsize(backup_graph_path),
                    'modified': datetime.fromtimestamp(os.path.getmtime(backup_graph_path)),
                    'status': 'â³ å¾…åŠ è½½'
                }
                self.log(f"ğŸ“ˆ é€‰æ‹©å¤‡ç”¨å›¾æ•°æ®æ–‡ä»¶: {backup_graph_path}")
            else:
                self.log(f"å¤‡ç”¨å›¾æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {backup_graph_path}")
        
        if not data_files:
             self.log("â€¼ï¸ é‡è¦è­¦å‘Š: æœªèƒ½å®šä½ä»»ä½•æ ¸å¿ƒæ•°æ®æ–‡ä»¶ (loops, metrics, graph)ã€‚GUIå¯èƒ½æ— æ³•æ­£å¸¸åŠ è½½æ•°æ®ã€‚")
        self.log(f"ğŸ” æ•°æ®æ–‡ä»¶æ‰«æå®Œæˆ. æ‰¾åˆ°çš„æ•°æ®: {list(data_files.keys())}")
        return data_files
    
    def load_loops_data(self, file_path):
        """åŠ è½½ç¯è·¯æ•°æ®"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # è§£æç¯è·¯æ•°æ®ï¼ˆä¸ä½¿ç”¨ä¼°ç®—å€¼ï¼‰
        loops_data = {}
        
        # æå–è¯¦ç»†é—­ç¯ä¿¡æ¯
        detailed_section = re.split(r'## è¯¦ç»†é—­ç¯ä¿¡æ¯', content, 1)
        if len(detailed_section) < 2:
            return {}
        
        detailed_content = detailed_section[1]
        company_sections = re.split(r'### è‚¡ä¸œ: ', detailed_content)[1:]
        
        loop_id = 1
        for section in company_sections:
            lines = section.strip().split('\n')
            company_name = lines[0].strip()
            
            in_loop_section = False
            current_loop_type = ""
            
            for line in lines:
                if line.startswith('####'):
                    current_loop_type = line.replace('####', '').strip()
                    in_loop_section = True
                    continue
                
                if in_loop_section and line.strip() and not line.startswith('-'):
                    if re.match(r'^\d+\.', line):
                        loop_content = re.sub(r'^\d+\.\s*', '', line).strip()
                        
                        # æå–èŠ‚ç‚¹è·¯å¾„å’Œè§’è‰²
                        node_path, node_roles = self.extract_nodes_from_content(loop_content)
                        
                        loops_data[loop_id] = {
                            'source': company_name,
                            'content': loop_content,
                            'type': current_loop_type,
                            'node_path': node_path,
                            'node_roles': node_roles,
                            'node_count': len(set(node_path)),
                            'has_real_data': False  # æ ‡è®°æ˜¯å¦æœ‰çœŸå®æ•°æ®
                        }
                        loop_id += 1
        
        return loops_data
    
    def extract_nodes_from_content(self, content):
        """ä»ç¯è·¯å†…å®¹ä¸­æå–èŠ‚ç‚¹ä¿¡æ¯"""
        node_path = []
        node_roles = []
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–èŠ‚ç‚¹å’Œè§’è‰²
        pattern = r'([^[\]]+?)\s*\[([^\]]+)\]'
        matches = re.findall(pattern, content)
        
        for node_name, node_role in matches:
            node_path.append(node_name.strip())
            node_roles.append(node_role.strip())
        
        return node_path, node_roles
    
    def load_metrics_data(self, file_path):
        """åŠ è½½æŒ‡æ ‡æ•°æ®"""
        if file_path.endswith('.csv'):
            return pd.read_csv(file_path)
        else:
            return {}
    
    def load_graph_data(self, file_path):
        """åŠ è½½å›¾æ•°æ®"""
        try:
            return nx.read_graphml(file_path)
        except Exception as e:
            self.log_queue.put(f"å›¾æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
            return None
    
    def get_record_count(self, file_type):
        """è·å–è®°å½•æ•°é‡"""
        if file_type == 'loops':
            return len(self.raw_loops_data)
        elif file_type == 'metrics':
            return len(self.loop_metrics_data) if isinstance(self.loop_metrics_data, pd.DataFrame) else 0
        elif file_type == 'graph':
            return self.graph_data.number_of_nodes() if self.graph_data else 0
        return 0
    
    def update_ui_from_queues(self):
        """ä»é˜Ÿåˆ—æ›´æ–°UI"""
        # å¤„ç†è¿›åº¦æ›´æ–°
        try:
            while True:
                msg_type, value = self.progress_queue.get_nowait()
                if msg_type == 'progress':
                    self.progress_var.set(value)
                elif msg_type == 'update_data_tree':
                    self.update_data_tree()
                elif msg_type == 'update_loop_types':
                    self.update_loop_types()
                elif msg_type == 'update_overview':
                    self.update_overview()
        except queue.Empty:
            pass
        
        # å¤„ç†æ—¥å¿—æ›´æ–°
        try:
            while True:
                log_msg = self.log_queue.get_nowait()
                self.log(log_msg)
        except queue.Empty:
            pass
        
        # ç»§ç»­ç›‘å¬
        self.root.after(100, self.update_ui_from_queues)
    
    def update_data_tree(self):
        """æ›´æ–°æ•°æ®æºæ ‘ï¼Œæ˜¾ç¤ºæ›´è¯¦ç»†çš„ä¿¡æ¯å’Œå¼•æ“"""
        self.log("ğŸŒ³ æ›´æ–°æ•°æ®æºæ ‘ (update_data_tree)...")
        # æ¸…ç©ºç°æœ‰é¡¹
        for item in self.data_tree.get_children():
            self.data_tree.delete(item)
        
        # æ·»åŠ æ•°æ®æºä¿¡æ¯
        if not self.data_sources:
            self.log("æ•°æ®æºä¸ºç©ºï¼Œæ— æ³•æ›´æ–°æ ‘ã€‚")
            return

        for file_type, file_info in self.data_sources.items():
            if not file_info or 'path' not in file_info : # ç¡®ä¿file_infoæœ‰æ•ˆ
                self.log(f"è­¦å‘Š: æ•°æ®æº '{file_type}' ä¿¡æ¯ä¸å®Œæ•´æˆ–æ— æ•ˆï¼Œè·³è¿‡ã€‚")
                continue

            self.log(f"æ›´æ–°æ ‘èŠ‚ç‚¹: {file_type}, ä¿¡æ¯: {file_info}")
            # æ·»åŠ å¼•æ“ä¿¡æ¯åˆ°æ˜¾ç¤ºåç§°
            engine_info = file_info.get('engine', '') # è·å–å¼•æ“ï¼Œé»˜è®¤ä¸ºç©ºå­—ç¬¦ä¸²
            display_name = f"{file_type.upper()}"
            if engine_info:
                display_name += f" ({engine_info})"
            
            # è·å–æ–‡ä»¶å¤§å°ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä¸º0
            size_bytes = file_info.get('size', 0)
            size_kb = f"{size_bytes / 1024:.1f}KB" if size_bytes else "N/A"

            # è·å–è®°å½•æ•°ï¼Œä¸å­˜åœ¨åˆ™ä¸º0
            records_count = file_info.get('records', 0)
            records_display = f"{records_count:,}" if records_count is not None else "N/A"

            # è·å–ä¿®æ”¹æ—¶é—´ï¼Œä¸å­˜åœ¨åˆ™ä¸ºN/A
            modified_time = file_info.get('modified')
            modified_display = modified_time.strftime('%Y-%m-%d %H:%M') if modified_time else "N/A"
            
            status_display = file_info.get('status', 'æœªçŸ¥')


            self.data_tree.insert('', 'end', 
                                 text=display_name,
                                 values=(
                                     status_display,
                                     records_display,
                                     modified_display,
                                     size_kb  # æ·»åŠ æ–‡ä»¶å¤§å°
                                 ))
        self.log("æ•°æ®æºæ ‘æ›´æ–°å®Œæ¯•ã€‚")
    
    def update_loop_types(self):
        """æ›´æ–°ç¯è·¯ç±»å‹é€‰æ‹©"""
        # æ¸…ç©ºç°æœ‰çš„å¤é€‰æ¡†
        for widget in self.loop_type_frame.winfo_children():
            widget.destroy()
        
        # è·å–æ‰€æœ‰å¯ç”¨çš„ç¯è·¯ç±»å‹
        if self.raw_loops_data:
            loop_types = set()
            for loop_data in self.raw_loops_data.values():
                loop_types.add(loop_data['type'])
            
            # åˆ›å»ºå¤é€‰æ¡†
            self.loop_type_vars = {}
            for i, loop_type in enumerate(sorted(loop_types)):
                var = tk.BooleanVar(value=True)  # é»˜è®¤å…¨é€‰
                self.loop_type_vars[loop_type] = var
                
                cb = ttk.Checkbutton(self.loop_type_frame, 
                                   text=loop_type,
                                   variable=var,
                                   command=self.on_loop_type_change)
                cb.grid(row=i//2, column=i%2, sticky='w', padx=5, pady=2)
    
    def update_overview(self):
        """æ›´æ–°æ•°æ®æ¦‚è§ˆ"""
        overview_text = self.generate_overview_text()
        self.stats_text.delete(1.0, tk.END)
        self.stats_text.insert(1.0, overview_text)
    
    def generate_overview_text(self):
        """ç”Ÿæˆæ¦‚è§ˆæ–‡æœ¬"""
        text = "ğŸ” ç‰©äº§ä¸­å¤§å›¾é£æ§ç³»ç»Ÿ - æ•°æ®æ¦‚è§ˆ\n"
        text += "=" * 60 + "\n\n"
        
        # æ•°æ®æºç»Ÿè®¡
        text += "ğŸ“Š æ•°æ®æºç»Ÿè®¡:\n"
        text += "-" * 30 + "\n"
        
        for file_type, file_info in self.data_sources.items():
            text += f"{file_type.upper():<10}: {file_info['status']} "
            text += f"({file_info.get('records', 0):,} æ¡è®°å½•)\n"
        
        text += "\n"
        
        # ç¯è·¯ç»Ÿè®¡
        if self.raw_loops_data:
            text += "ğŸ”„ ç¯è·¯ç»Ÿè®¡:\n"
            text += "-" * 30 + "\n"
            text += f"æ€»ç¯è·¯æ•°é‡: {len(self.raw_loops_data):,}\n"
            
            # æŒ‰ç±»å‹ç»Ÿè®¡
            type_counts = Counter()
            node_counts = Counter()
            
            for loop_data in self.raw_loops_data.values():
                type_counts[loop_data['type']] += 1
                node_counts[loop_data['node_count']] += 1
            
            text += "\næŒ‰ç±»å‹åˆ†å¸ƒ:\n"
            for loop_type, count in type_counts.most_common():
                text += f"  {loop_type}: {count:,} ä¸ª\n"
            
            text += "\næŒ‰èŠ‚ç‚¹æ•°åˆ†å¸ƒ:\n"
            for node_count, count in sorted(node_counts.items()):
                text += f"  {node_count}èŠ‚ç‚¹: {count:,} ä¸ª\n"
        
        # å¦‚æœæœ‰æŒ‡æ ‡æ•°æ®
        if isinstance(self.loop_metrics_data, pd.DataFrame) and not self.loop_metrics_data.empty:
            text += "\nğŸ’° äº¤æ˜“æŒ‡æ ‡ç»Ÿè®¡:\n"
            text += "-" * 30 + "\n"
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            if 'total_transaction_amount' in self.loop_metrics_data.columns:
                amounts = self.loop_metrics_data['total_transaction_amount'].dropna()
                if len(amounts) > 0:
                    text += f"å¹³å‡äº¤æ˜“é‡‘é¢: {amounts.mean()/10000:.1f} ä¸‡å…ƒ\n"
                    text += f"æœ€å¤§äº¤æ˜“é‡‘é¢: {amounts.max()/10000:.1f} ä¸‡å…ƒ\n"
                    text += f"ä¸­ä½æ•°äº¤æ˜“é‡‘é¢: {amounts.median()/10000:.1f} ä¸‡å…ƒ\n"
        
        # ç³»ç»ŸçŠ¶æ€
        text += "\nâš™ï¸ ç³»ç»ŸçŠ¶æ€:\n"
        text += "-" * 30 + "\n"
        text += f"æ•°æ®åŠ è½½æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        text += f"å¯ç”¨ç¯è·¯ç±»å‹: {len(self.loop_type_vars)} ç§\n"
        
        return text
    
    def on_loop_type_change(self):
        """ç¯è·¯ç±»å‹é€‰æ‹©å˜åŒ–"""
        selected_types = []
        for loop_type, var in self.loop_type_vars.items():
            if var.get():
                selected_types.append(loop_type)
        
        self.filter_params['selected_loop_types'] = selected_types
        self.update_filter_preview()
    
    def update_filter_preview(self):
        """æ›´æ–°ç­›é€‰é¢„è§ˆ"""
        if not self.raw_loops_data:
            return
        
        # åº”ç”¨å½“å‰ç­›é€‰æ¡ä»¶è®¡ç®—é¢„è§ˆç»“æœ
        filtered_count = self.calculate_filtered_count()
        
        self.status_var.set(f"ç­›é€‰é¢„è§ˆ: {filtered_count:,} / {len(self.raw_loops_data):,} ä¸ªç¯è·¯æ»¡è¶³æ¡ä»¶")
    
    def calculate_filtered_count(self):
        """è®¡ç®—ç­›é€‰åçš„æ•°é‡ï¼ˆå¿«é€Ÿé¢„è§ˆï¼‰"""
        count = 0
        selected_types = self.filter_params['selected_loop_types']
        min_nodes = self.filter_params['min_nodes'].get()
        max_nodes = self.filter_params['max_nodes'].get()
        
        for loop_data in self.raw_loops_data.values():
            # ç±»å‹ç­›é€‰
            if selected_types and loop_data['type'] not in selected_types:
                continue
            
            # èŠ‚ç‚¹æ•°ç­›é€‰
            if not (min_nodes <= loop_data['node_count'] <= max_nodes):
                continue
            
            count += 1
        
        return count
    
    def execute_filtering(self):
        """æ‰§è¡Œå®Œæ•´ç­›é€‰"""
        if not self.raw_loops_data:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½ç¯è·¯æ•°æ®")
            return
        
        self.log("ğŸ¯ å¼€å§‹æ‰§è¡Œé«˜çº§ç­›é€‰...")
        
        # åœ¨åå°çº¿ç¨‹æ‰§è¡Œç­›é€‰
        threading.Thread(target=self._execute_filtering_worker, daemon=True).start()
    
    def _execute_filtering_worker(self):
        """ç­›é€‰å·¥ä½œçº¿ç¨‹"""
        try:
            filtered_results = []
            
            total_loops = len(self.raw_loops_data)
            processed = 0
            
            for loop_id, loop_data in self.raw_loops_data.items():
                # åº”ç”¨æ‰€æœ‰ç­›é€‰æ¡ä»¶
                if self.apply_all_filters(loop_id, loop_data):
                    # è®¡ç®—è¯¦ç»†æŒ‡æ ‡
                    metrics = self.calculate_detailed_metrics(loop_id, loop_data)
                    
                    result = {
                        'loop_id': loop_id,
                        'type': loop_data['type'],
                        'node_count': loop_data['node_count'],
                        'content': loop_data['content'],
                        **metrics
                    }
                    filtered_results.append(result)
                
                processed += 1
                if processed % 100 == 0:
                    progress = processed / total_loops * 100
                    self.progress_queue.put(('progress', progress))
            
            # æŒ‰æ—¶é—´é—´éš”æ’åº
            filtered_results.sort(key=lambda x: x.get('time_gap_days', 999), reverse=False)
            
            # é™åˆ¶ç»“æœæ•°é‡
            max_results = self.filter_params['max_results'].get()
            filtered_results = filtered_results[:max_results]
            
            # æ›´æ–°ç»“æœ
            self.filtered_results = pd.DataFrame(filtered_results)
            
            self.progress_queue.put(('progress', 100))
            self.log_queue.put(f"âœ… ç­›é€‰å®Œæˆ: {len(filtered_results)} ä¸ªç¯è·¯æ»¡è¶³æ¡ä»¶")
            
            # æ›´æ–°UI
            self.progress_queue.put(('update_results', None))
            self.progress_queue.put(('update_charts', None))
            
        except Exception as e:
            self.log_queue.put(f"âŒ ç­›é€‰è¿‡ç¨‹å‡ºé”™: {str(e)}")
    
    def apply_all_filters(self, loop_id, loop_data):
        """åº”ç”¨æ‰€æœ‰ç­›é€‰æ¡ä»¶"""
        # 1. ç±»å‹ç­›é€‰
        selected_types = self.filter_params['selected_loop_types']
        if selected_types and loop_data['type'] not in selected_types:
            return False
        
        # 2. èŠ‚ç‚¹æ•°ç­›é€‰
        min_nodes = self.filter_params['min_nodes'].get()
        max_nodes = self.filter_params['max_nodes'].get()
        if not (min_nodes <= loop_data['node_count'] <= max_nodes):
            return False
        
        # 3. æ—¶é—´ç»´åº¦ç­›é€‰ï¼ˆå¦‚æœæœ‰å›¾æ•°æ®å’ŒæŒ‡æ ‡æ•°æ®ï¼‰
        if self.graph_data and isinstance(self.loop_metrics_data, pd.DataFrame):
            if not self.apply_time_filters(loop_id, loop_data):
                return False
        
        # 4. é‡‘é¢ç­›é€‰ï¼ˆå¦‚æœæœ‰æŒ‡æ ‡æ•°æ®ï¼‰
        if isinstance(self.loop_metrics_data, pd.DataFrame):
            if not self.apply_amount_filters(loop_id, loop_data):
                return False
        
        # 5. è‚¡æƒç­›é€‰ï¼ˆå¦‚æœæœ‰å›¾æ•°æ®ï¼‰
        if self.graph_data:
            if not self.apply_equity_filters(loop_id, loop_data):
                return False
        
        return True
    
    def apply_time_filters(self, loop_id, loop_data):
        """åº”ç”¨æ—¶é—´ç»´åº¦ç­›é€‰"""
        # è¿™é‡Œéœ€è¦å®ç°æ—¶é—´ç»´åº¦çš„å¤æ‚é€»è¾‘
        # åˆ†æä¸Šæ¸¸äº¤æ˜“å’Œä¸‹æ¸¸äº¤æ˜“çš„æ—¶é—´é—´éš”
        
        try:
            # ä»æŒ‡æ ‡æ•°æ®ä¸­è·å–æ—¶é—´ä¿¡æ¯
            metrics_row = self.loop_metrics_data[self.loop_metrics_data['loop_id'] == loop_id]
            if metrics_row.empty:
                return True  # æ²¡æœ‰æ•°æ®åˆ™é€šè¿‡
            
            # æ£€æŸ¥ä¸Šä¸‹æ¸¸äº¤æ˜“æ—¶é—´é—´éš”
            if 'upstream_to_member_transaction_times' in metrics_row.columns:
                upstream_times = metrics_row.iloc[0]['upstream_to_member_transaction_times']
                downstream_times = metrics_row.iloc[0]['member_to_downstream_transaction_times']
                
                if upstream_times and downstream_times:
                    # è®¡ç®—æ—¶é—´é—´éš”
                    time_gap = self.calculate_time_gap(upstream_times, downstream_times)
                    max_gap = self.filter_params['max_time_gap_days'].get()
                    
                    if time_gap > max_gap:
                        return False
            
            return True
            
        except Exception:
            return True  # å‡ºé”™åˆ™é€šè¿‡ç­›é€‰
    
    def calculate_time_gap(self, upstream_times, downstream_times):
        """è®¡ç®—ä¸Šä¸‹æ¸¸äº¤æ˜“æ—¶é—´é—´éš”"""
        try:
            # è§£ææ—¶é—´å­—ç¬¦ä¸²
            if isinstance(upstream_times, str):
                upstream_times = eval(upstream_times) if upstream_times.startswith('[') else [upstream_times]
            if isinstance(downstream_times, str):
                downstream_times = eval(downstream_times) if downstream_times.startswith('[') else [downstream_times]
            
            if not upstream_times or not downstream_times:
                return 0
            
            # è·å–æœ€åä¸€æ¬¡äº¤æ˜“æ—¶é—´
            last_upstream = max(upstream_times)
            last_downstream = max(downstream_times)
            
            # è®¡ç®—æ—¶é—´å·®
            upstream_date = datetime.strptime(last_upstream.split()[0], '%Y-%m-%d')
            downstream_date = datetime.strptime(last_downstream.split()[0], '%Y-%m-%d')
            
            return abs((downstream_date - upstream_date).days)
            
        except Exception:
            return 0
    
    def apply_amount_filters(self, loop_id, loop_data):
        """åº”ç”¨é‡‘é¢ç­›é€‰"""
        try:
            metrics_row = self.loop_metrics_data[self.loop_metrics_data['loop_id'] == loop_id]
            if metrics_row.empty:
                return True
            
            row = metrics_row.iloc[0]
            
            # æ£€æŸ¥æ€»äº¤æ˜“é‡‘é¢
            min_total = self.filter_params['min_total_amount'].get() * 10000
            if row.get('total_transaction_amount', 0) < min_total:
                return False
            
            # æ£€æŸ¥ä¸Šæ¸¸äº¤æ˜“é‡‘é¢
            min_upstream = self.filter_params['min_upstream_amount'].get() * 10000
            if row.get('upstream_to_member_transaction_amount', 0) < min_upstream:
                return False
            
            # æ£€æŸ¥ä¸‹æ¸¸äº¤æ˜“é‡‘é¢
            min_downstream = self.filter_params['min_downstream_amount'].get() * 10000
            if row.get('member_to_downstream_transaction_amount', 0) < min_downstream:
                return False
            
            return True
            
        except Exception:
            return True
    
    def apply_equity_filters(self, loop_id, loop_data):
        """åº”ç”¨è‚¡æƒç­›é€‰"""
        try:
            # ä½¿ç”¨å›¾æ•°æ®åˆ†æè‚¡æƒç»“æ„
            node_path = loop_data['node_path']
            
            if not node_path or not self.graph_data:
                return True
            
            # åˆ†æç¯è·¯ä¸­çš„è‚¡æƒå…³ç³»
            equity_ratios = []
            for node_name in node_path:
                # åœ¨å›¾ä¸­æŸ¥æ‰¾å¯¹åº”èŠ‚ç‚¹
                node_id = self.find_node_in_graph(node_name)
                if node_id:
                    # è·å–æŒè‚¡ä¿¡æ¯
                    ratios = self.get_equity_ratios(node_id)
                    equity_ratios.extend(ratios)
            
            if equity_ratios:
                min_ratio = self.filter_params['min_equity_ratio'].get()
                max_ratio = self.filter_params['max_equity_ratio'].get()
                
                # æ£€æŸ¥æ˜¯å¦æœ‰åœ¨èŒƒå›´å†…çš„è‚¡æƒæ¯”ä¾‹
                valid_ratios = [r for r in equity_ratios if min_ratio <= r <= max_ratio]
                return len(valid_ratios) > 0
            
            return True
            
        except Exception:
            return True
    
    def find_node_in_graph(self, node_name):
        """åœ¨å›¾ä¸­æŸ¥æ‰¾èŠ‚ç‚¹"""
        if not self.graph_data:
            return None
        
        for node_id, attributes in self.graph_data.nodes(data=True):
            if attributes.get('name') == node_name:
                return node_id
        
        return None
    
    def get_equity_ratios(self, node_id):
        """è·å–èŠ‚ç‚¹çš„è‚¡æƒæ¯”ä¾‹"""
        ratios = []
        
        try:
            # è·å–å‡ºè¾¹ï¼ˆæŠ•èµ„å…³ç³»ï¼‰
            for _, target, edge_data in self.graph_data.out_edges(node_id, data=True):
                percent = edge_data.get('percent', 0)
                if isinstance(percent, (int, float)) and percent > 0:
                    ratios.append(percent * 100)  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        except Exception:
            pass
        
        return ratios
    
    def calculate_detailed_metrics(self, loop_id, loop_data):
        """è®¡ç®—è¯¦ç»†æŒ‡æ ‡ï¼ˆåªä½¿ç”¨çœŸå®æ•°æ®ï¼‰"""
        metrics = {
            'upstream_amount': 0,
            'downstream_amount': 0,
            'total_amount': 0,
            'time_gap_days': 999,
            'equity_concentration': 0,
            'last_transaction_date': 'N/A'
        }
        
        try:
            # ä»æŒ‡æ ‡æ•°æ®è·å–çœŸå®æŒ‡æ ‡
            if isinstance(self.loop_metrics_data, pd.DataFrame):
                metrics_row = self.loop_metrics_data[self.loop_metrics_data['loop_id'] == loop_id]
                if not metrics_row.empty:
                    row = metrics_row.iloc[0]
                    
                    metrics['upstream_amount'] = row.get('upstream_to_member_transaction_amount', 0) / 10000
                    metrics['downstream_amount'] = row.get('member_to_downstream_transaction_amount', 0) / 10000
                    metrics['total_amount'] = row.get('total_transaction_amount', 0) / 10000
                    
                    # è®¡ç®—æ—¶é—´é—´éš”
                    upstream_times = row.get('upstream_to_member_transaction_times', [])
                    downstream_times = row.get('member_to_downstream_transaction_times', [])
                    
                    if upstream_times and downstream_times:
                        metrics['time_gap_days'] = self.calculate_time_gap(upstream_times, downstream_times)
                        
                        # è·å–æœ€åäº¤æ˜“æ—¶é—´
                        all_times = []
                        if isinstance(upstream_times, str):
                            upstream_times = eval(upstream_times) if upstream_times.startswith('[') else [upstream_times]
                        if isinstance(downstream_times, str):
                            downstream_times = eval(downstream_times) if downstream_times.startswith('[') else [downstream_times]
                        
                        all_times.extend(upstream_times)
                        all_times.extend(downstream_times)
                        
                        if all_times:
                            metrics['last_transaction_date'] = max(all_times)
            
            # è®¡ç®—è‚¡æƒé›†ä¸­åº¦
            if self.graph_data:
                node_path = loop_data['node_path']
                equity_ratios = []
                
                for node_name in node_path:
                    node_id = self.find_node_in_graph(node_name)
                    if node_id:
                        ratios = self.get_equity_ratios(node_id)
                        equity_ratios.extend(ratios)
                
                if equity_ratios:
                    # ä½¿ç”¨HHIæŒ‡æ•°è®¡ç®—é›†ä¸­åº¦
                    total = sum(equity_ratios)
                    if total > 0:
                        hhi = sum((r/total)**2 for r in equity_ratios)
                        metrics['equity_concentration'] = hhi
        
        except Exception as e:
            self.log(f"è®¡ç®—æŒ‡æ ‡æ—¶å‡ºé”™: {str(e)}")
        
        return metrics
    
    def run_sanity_check(self):
        """è¿è¡Œå®Œæ•´æ€§æ£€æŸ¥"""
        self.log("ğŸ” å¼€å§‹è¿è¡Œæ•°æ®å®Œæ•´æ€§æ£€æŸ¥...")
        
        threading.Thread(target=self._sanity_check_worker, daemon=True).start()
    
    def _sanity_check_worker(self):
        """å®Œæ•´æ€§æ£€æŸ¥å·¥ä½œçº¿ç¨‹"""
        try:
            issues = []
            
            # æ£€æŸ¥æ•°æ®æºå®Œæ•´æ€§
            if not self.raw_loops_data:
                issues.append("âŒ ç¼ºå°‘ç¯è·¯æ•°æ®")
            
            if not isinstance(self.loop_metrics_data, pd.DataFrame) or self.loop_metrics_data.empty:
                issues.append("âš ï¸ ç¼ºå°‘æŒ‡æ ‡æ•°æ® - å°†æ— æ³•è¿›è¡Œé«˜çº§ç­›é€‰")
            
            if not self.graph_data:
                issues.append("âš ï¸ ç¼ºå°‘å›¾æ•°æ® - å°†æ— æ³•è¿›è¡Œè‚¡æƒåˆ†æ")
            
            # æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
            if self.raw_loops_data and isinstance(self.loop_metrics_data, pd.DataFrame):
                loop_ids = set(self.raw_loops_data.keys())
                metric_ids = set(self.loop_metrics_data['loop_id'].tolist())
                
                missing_metrics = loop_ids - metric_ids
                extra_metrics = metric_ids - loop_ids
                
                if missing_metrics:
                    issues.append(f"âš ï¸ {len(missing_metrics)} ä¸ªç¯è·¯ç¼ºå°‘æŒ‡æ ‡æ•°æ®")
                
                if extra_metrics:
                    issues.append(f"âš ï¸ {len(extra_metrics)} ä¸ªæŒ‡æ ‡è®°å½•æ‰¾ä¸åˆ°å¯¹åº”ç¯è·¯")
            
            # æ£€æŸ¥ç¯è·¯ç±»å‹å®Œæ•´æ€§
            if self.raw_loops_data:
                type_counts = Counter()
                for loop_data in self.raw_loops_data.values():
                    type_counts[loop_data['type']] += 1
                
                expected_types = ['4èŠ‚ç‚¹ç¯è·¯', '5èŠ‚ç‚¹ç¯è·¯', '6èŠ‚ç‚¹ç¯è·¯', '7èŠ‚ç‚¹ç¯è·¯', '8èŠ‚ç‚¹ç¯è·¯']
                missing_types = [t for t in expected_types if t not in type_counts]
                
                if missing_types:
                    issues.append(f"âš ï¸ ç¼ºå°‘ä»¥ä¸‹ç¯è·¯ç±»å‹: {', '.join(missing_types)}")
            
            # ç”ŸæˆæŠ¥å‘Š
            if not issues:
                self.log_queue.put("âœ… æ•°æ®å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡ - æ‰€æœ‰æ•°æ®å®Œæ•´ä¸”ä¸€è‡´")
            else:
                self.log_queue.put("âš ï¸ æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å‘ç°é—®é¢˜:")
                for issue in issues:
                    self.log_queue.put(f"  {issue}")
            
            # æ›´æ–°çŠ¶æ€
            self.progress_queue.put(('progress', 0))
            
        except Exception as e:
            self.log_queue.put(f"âŒ å®Œæ•´æ€§æ£€æŸ¥å‡ºé”™: {str(e)}")
    
    def run_equity_analysis(self):
        """è¿è¡Œè‚¡æƒåˆ†æï¼ˆè°ƒç”¨loop_filter_scriptï¼‰"""
        self.log("ğŸ“Š å¼€å§‹è¿è¡Œè‚¡æƒåˆ†æ...")
        
        threading.Thread(target=self._equity_analysis_worker, daemon=True).start()
    
    def _equity_analysis_worker(self):
        """è‚¡æƒåˆ†æå·¥ä½œçº¿ç¨‹"""
        try:
            # è°ƒç”¨loop_filter_scriptè¿›è¡Œè‚¡æƒåˆ†æ
            script_path = "../code/loop_filter_script.py"  # ç›¸å¯¹è·¯å¾„
            
            if not os.path.exists(script_path):
                script_path = "loop_filter_script.py"  # å½“å‰ç›®å½•
            
            if not os.path.exists(script_path):
                self.log_queue.put("âŒ æ‰¾ä¸åˆ°loop_filter_script.pyæ–‡ä»¶")
                return
            
            self.log_queue.put("ğŸ”„ æ­£åœ¨è°ƒç”¨è‚¡æƒåˆ†æè„šæœ¬...")
            
            # æ„å»ºå‘½ä»¤å‚æ•°
            cmd = [
                "python", script_path,
                "--min-amount", str(self.filter_params['min_total_amount'].get() * 10000),
                "--min-frequency", str(self.filter_params['min_upstream_transactions'].get()),
                "--min-risk-score", "0.1",  # ä½¿ç”¨è¾ƒä½é˜ˆå€¼è·å–æ›´å¤šæ•°æ®
                "--top-k", str(self.filter_params['max_results'].get())
            ]
            
            # æ‰§è¡Œè„šæœ¬
            result = subprocess.run(cmd, capture_output=True, text=True, cwd="..")
            
            if result.returncode == 0:
                self.log_queue.put("âœ… è‚¡æƒåˆ†æå®Œæˆ")
                self.log_queue.put("ğŸ“„ åˆ†æç»“æœå·²ä¿å­˜åˆ° outputs/loop_filter/ ç›®å½•")
                
                # å°è¯•åŠ è½½åˆ†æç»“æœ
                self.load_equity_analysis_results()
                
            else:
                self.log_queue.put(f"âŒ è‚¡æƒåˆ†æå¤±è´¥: {result.stderr}")
            
        except Exception as e:
            self.log_queue.put(f"âŒ è‚¡æƒåˆ†æå‡ºé”™: {str(e)}")
    
    def load_equity_analysis_results(self):
        """åŠ è½½è‚¡æƒåˆ†æç»“æœ"""
        try:
            results_path = "../outputs/loop_filter/filter_report.csv"
            if os.path.exists(results_path):
                equity_results = pd.read_csv(results_path)
                self.log_queue.put(f"ğŸ“Š åŠ è½½è‚¡æƒåˆ†æç»“æœ: {len(equity_results)} æ¡è®°å½•")
                
                # å°†ç»“æœæ•´åˆåˆ°å½“å‰æ•°æ®ä¸­
                self.integrate_equity_results(equity_results)
            
        except Exception as e:
            self.log_queue.put(f"âŒ åŠ è½½è‚¡æƒåˆ†æç»“æœå¤±è´¥: {str(e)}")
    
    def integrate_equity_results(self, equity_results):
        """æ•´åˆè‚¡æƒåˆ†æç»“æœ"""
        # å°†è‚¡æƒåˆ†æç»“æœä¸ç°æœ‰æ•°æ®åˆå¹¶
        # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦å®ç°å…·ä½“çš„æ•´åˆé€»è¾‘
        pass
    
    def reload_all_data(self):
        """é‡æ–°åŠ è½½æ‰€æœ‰æ•°æ®"""
        self.log("ğŸ”„ é‡æ–°åŠ è½½æ‰€æœ‰æ•°æ®...")
        
        # æ¸…ç©ºç°æœ‰æ•°æ®
        self.raw_loops_data = {}
        self.loop_metrics_data = {}
        self.graph_data = None
        self.data_sources = {}
        
        # é‡æ–°è‡ªåŠ¨åŠ è½½
        self.auto_load_data()
    
    def reset_parameters(self):
        """é‡ç½®æ‰€æœ‰å‚æ•°åˆ°é»˜è®¤å€¼"""
        self.filter_params['time_window_months'].set(12)
        self.filter_params['max_time_gap_days'].set(30)
        self.filter_params['min_upstream_transactions'].set(1)
        self.filter_params['min_downstream_transactions'].set(1)
        
        self.filter_params['min_total_amount'].set(0)
        self.filter_params['min_upstream_amount'].set(0)
        self.filter_params['min_downstream_amount'].set(0)
        
        self.filter_params['min_equity_ratio'].set(0)
        self.filter_params['max_equity_ratio'].set(100)
        self.filter_params['min_shareholders'].set(1)
        
        self.filter_params['min_nodes'].set(3)
        self.filter_params['max_nodes'].set(15)
        self.filter_params['max_results'].set(1000)
        
        # é‡ç½®ç¯è·¯ç±»å‹é€‰æ‹©
        for var in self.loop_type_vars.values():
            var.set(True)
        
        self.log("âœ… å‚æ•°å·²é‡ç½®ä¸ºé»˜è®¤å€¼")
    
    def update_results_display(self):
        """æ›´æ–°ç»“æœæ˜¾ç¤º"""
        # æ¸…ç©ºç°æœ‰ç»“æœ
        for item in self.results_tree.get_children():
            self.results_tree.delete(item)
        
        if self.filtered_results.empty:
            return
        
        # æ·»åŠ ç­›é€‰ç»“æœ
        for _, row in self.filtered_results.iterrows():
            values = [
                int(row['loop_id']),
                row['type'],
                int(row['node_count']),
                f"{row['upstream_amount']:.1f}ä¸‡",
                f"{row['downstream_amount']:.1f}ä¸‡",
                f"{row['time_gap_days']}å¤©",
                f"{row['equity_concentration']:.3f}",
                str(row['last_transaction_date'])[:10]
            ]
            self.results_tree.insert('', 'end', values=values)
    
    def update_charts(self):
        """æ›´æ–°å›¾è¡¨æ˜¾ç¤º"""
        if self.filtered_results.empty:
            return
        
        # æ›´æ–°æ—¶é—´åˆ†æå›¾è¡¨
        self.update_time_chart()
        
        # æ›´æ–°è‚¡æƒåˆ†æå›¾è¡¨
        self.update_equity_chart()
    
    def update_time_chart(self):
        """æ›´æ–°æ—¶é—´åˆ†æå›¾è¡¨"""
        self.time_fig.clear()
        
        if 'time_gap_days' not in self.filtered_results.columns:
            return
        
        # åˆ›å»ºå­å›¾
        ax1 = self.time_fig.add_subplot(221)
        ax2 = self.time_fig.add_subplot(222)
        ax3 = self.time_fig.add_subplot(223)
        ax4 = self.time_fig.add_subplot(224)
        
        # 1. æ—¶é—´é—´éš”åˆ†å¸ƒ
        time_gaps = self.filtered_results['time_gap_days'].dropna()
        ax1.hist(time_gaps, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        ax1.set_xlabel('æ—¶é—´é—´éš” (å¤©)')
        ax1.set_ylabel('é¢‘æ•°')
        ax1.set_title('ä¸Šä¸‹æ¸¸äº¤æ˜“æ—¶é—´é—´éš”åˆ†å¸ƒ')
        ax1.grid(True, alpha=0.3)
        
        # 2. äº¤æ˜“é‡‘é¢vsæ—¶é—´é—´éš”
        if 'total_amount' in self.filtered_results.columns:
            ax2.scatter(self.filtered_results['time_gap_days'], 
                       self.filtered_results['total_amount'],
                       alpha=0.6, s=50)
            ax2.set_xlabel('æ—¶é—´é—´éš” (å¤©)')
            ax2.set_ylabel('æ€»äº¤æ˜“é‡‘é¢ (ä¸‡å…ƒ)')
            ax2.set_title('äº¤æ˜“é‡‘é¢ vs æ—¶é—´é—´éš”')
            ax2.grid(True, alpha=0.3)
        
        # 3. ç¯è·¯ç±»å‹vsæ—¶é—´é—´éš”
        if 'type' in self.filtered_results.columns:
            type_gaps = {}
            for loop_type in self.filtered_results['type'].unique():
                type_gaps[loop_type] = self.filtered_results[
                    self.filtered_results['type'] == loop_type]['time_gap_days'].tolist()
            
            ax3.boxplot(type_gaps.values(), labels=type_gaps.keys())
            ax3.set_xlabel('ç¯è·¯ç±»å‹')
            ax3.set_ylabel('æ—¶é—´é—´éš” (å¤©)')
            ax3.set_title('ä¸åŒç±»å‹ç¯è·¯çš„æ—¶é—´é—´éš”')
            ax3.tick_params(axis='x', rotation=45)
        
        # 4. æœˆåº¦è¶‹åŠ¿ï¼ˆå¦‚æœæœ‰è¶³å¤Ÿçš„æ—¶é—´æ•°æ®ï¼‰
        ax4.text(0.5, 0.5, 'æœˆåº¦è¶‹åŠ¿åˆ†æ\n(éœ€è¦æ›´å¤šæ—¶é—´æ•°æ®)', 
                ha='center', va='center', transform=ax4.transAxes)
        ax4.set_title('æœˆåº¦è¶‹åŠ¿åˆ†æ')
        
        self.time_fig.tight_layout()
        self.time_canvas.draw()
    
    def update_equity_chart(self):
        """æ›´æ–°è‚¡æƒåˆ†æå›¾è¡¨"""
        self.equity_fig.clear()
        
        if 'equity_concentration' not in self.filtered_results.columns:
            return
        
        # åˆ›å»ºå­å›¾
        ax1 = self.equity_fig.add_subplot(221)
        ax2 = self.equity_fig.add_subplot(222)
        ax3 = self.equity_fig.add_subplot(223)
        ax4 = self.equity_fig.add_subplot(224)
        
        # 1. è‚¡æƒé›†ä¸­åº¦åˆ†å¸ƒ
        equity_conc = self.filtered_results['equity_concentration'].dropna()
        ax1.hist(equity_conc, bins=20, alpha=0.7, color='lightcoral', edgecolor='black')
        ax1.set_xlabel('è‚¡æƒé›†ä¸­åº¦')
        ax1.set_ylabel('é¢‘æ•°')
        ax1.set_title('è‚¡æƒé›†ä¸­åº¦åˆ†å¸ƒ')
        ax1.grid(True, alpha=0.3)
        
        # 2. è‚¡æƒé›†ä¸­åº¦vsäº¤æ˜“é‡‘é¢
        if 'total_amount' in self.filtered_results.columns:
            ax2.scatter(self.filtered_results['equity_concentration'], 
                       self.filtered_results['total_amount'],
                       alpha=0.6, s=50, c='red')
            ax2.set_xlabel('è‚¡æƒé›†ä¸­åº¦')
            ax2.set_ylabel('æ€»äº¤æ˜“é‡‘é¢ (ä¸‡å…ƒ)')
            ax2.set_title('è‚¡æƒé›†ä¸­åº¦ vs äº¤æ˜“é‡‘é¢')
            ax2.grid(True, alpha=0.3)
        
        # 3. ä¸åŒèŠ‚ç‚¹æ•°çš„è‚¡æƒé›†ä¸­åº¦
        if 'node_count' in self.filtered_results.columns:
            node_equity = {}
            for node_count in sorted(self.filtered_results['node_count'].unique()):
                node_equity[f'{node_count}èŠ‚ç‚¹'] = self.filtered_results[
                    self.filtered_results['node_count'] == node_count]['equity_concentration'].tolist()
            
            ax3.boxplot(node_equity.values(), labels=node_equity.keys())
            ax3.set_xlabel('ç¯è·¯èŠ‚ç‚¹æ•°')
            ax3.set_ylabel('è‚¡æƒé›†ä¸­åº¦')
            ax3.set_title('ä¸åŒèŠ‚ç‚¹æ•°çš„è‚¡æƒé›†ä¸­åº¦')
        
        # 4. è‚¡æƒé£é™©è¯„ä¼°
        ax4.text(0.5, 0.5, 'è‚¡æƒé£é™©è¯„ä¼°\n(åŸºäºé›†ä¸­åº¦å’Œäº¤æ˜“æ¨¡å¼)', 
                ha='center', va='center', transform=ax4.transAxes)
        ax4.set_title('è‚¡æƒé£é™©è¯„ä¼°')
        
        self.equity_fig.tight_layout()
        self.equity_canvas.draw()
    
    def export_results(self):
        """å¯¼å‡ºç­›é€‰ç»“æœ"""
        if self.filtered_results.empty:
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰ç­›é€‰ç»“æœå¯ä»¥å¯¼å‡º")
            return
        
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = "../outputs/loop_filter_gui"
            os.makedirs(output_dir, exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"filtered_loops_{timestamp}.csv"
            filepath = os.path.join(output_dir, filename)
            
            # å¯¼å‡ºCSV
            self.filtered_results.to_csv(filepath, index=False, encoding='utf-8-sig')
            
            self.log(f"âœ… ç­›é€‰ç»“æœå·²å¯¼å‡ºåˆ°: {filepath}")
            messagebox.showinfo("æˆåŠŸ", f"ç­›é€‰ç»“æœå·²å¯¼å‡ºåˆ°:\n{filepath}")
            
        except Exception as e:
            self.log(f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")
            messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºå¤±è´¥: {str(e)}")
    
    def generate_report(self):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        if self.filtered_results.empty:
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰ç­›é€‰ç»“æœå¯ä»¥ç”ŸæˆæŠ¥å‘Š")
            return
        
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = "../outputs/loop_filter_gui"
            os.makedirs(output_dir, exist_ok=True)
            
            # ç”ŸæˆæŠ¥å‘Š
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"loop_analysis_report_{timestamp}.md"
            filepath = os.path.join(output_dir, filename)
            
            report_content = self.generate_report_content()
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            self.log(f"âœ… åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {filepath}")
            messagebox.showinfo("æˆåŠŸ", f"åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ:\n{filepath}")
            
        except Exception as e:
            self.log(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
            messagebox.showerror("é”™è¯¯", f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
    
    def generate_report_content(self):
        """ç”ŸæˆæŠ¥å‘Šå†…å®¹"""
        report = "# ç‰©äº§ä¸­å¤§å›¾é£æ§ç³»ç»Ÿ - é«˜çº§é—­ç¯ç­›é€‰åˆ†ææŠ¥å‘Š\n\n"
        report += f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        
        # ç­›é€‰å‚æ•°
        report += "## ç­›é€‰å‚æ•°é…ç½®\n\n"
        report += f"- åˆ†ææ—¶é—´çª—å£: {self.filter_params['time_window_months'].get()} ä¸ªæœˆ\n"
        report += f"- æœ€å¤§äº¤æ˜“æ—¶é—´é—´éš”: {self.filter_params['max_time_gap_days'].get()} å¤©\n"
        report += f"- æœ€å°æ€»äº¤æ˜“é‡‘é¢: {self.filter_params['min_total_amount'].get()} ä¸‡å…ƒ\n"
        report += f"- ç¯è·¯èŠ‚ç‚¹æ•°èŒƒå›´: {self.filter_params['min_nodes'].get()}-{self.filter_params['max_nodes'].get()}\n"
        report += f"- é€‰æ‹©çš„ç¯è·¯ç±»å‹: {len([v for v in self.loop_type_vars.values() if v.get()])} ç§\n\n"
        
        # ç­›é€‰ç»“æœç»Ÿè®¡
        report += "## ç­›é€‰ç»“æœç»Ÿè®¡\n\n"
        report += f"- åŸå§‹ç¯è·¯æ€»æ•°: {len(self.raw_loops_data):,}\n"
        report += f"- ç­›é€‰åç¯è·¯æ•°: {len(self.filtered_results):,}\n"
        report += f"- ç­›é€‰ç‡: {len(self.filtered_results)/len(self.raw_loops_data)*100:.2f}%\n\n"
        
        # å…³é”®å‘ç°
        if not self.filtered_results.empty:
            report += "## å…³é”®å‘ç°\n\n"
            
            # æ—¶é—´ç»´åº¦åˆ†æ
            if 'time_gap_days' in self.filtered_results.columns:
                avg_gap = self.filtered_results['time_gap_days'].mean()
                max_gap = self.filtered_results['time_gap_days'].max()
                min_gap = self.filtered_results['time_gap_days'].min()
                
                report += f"### æ—¶é—´ç»´åº¦åˆ†æ\n"
                report += f"- å¹³å‡äº¤æ˜“æ—¶é—´é—´éš”: {avg_gap:.1f} å¤©\n"
                report += f"- æœ€å¤§äº¤æ˜“æ—¶é—´é—´éš”: {max_gap} å¤©\n"
                report += f"- æœ€å°äº¤æ˜“æ—¶é—´é—´éš”: {min_gap} å¤©\n\n"
            
            # é‡‘é¢åˆ†æ
            if 'total_amount' in self.filtered_results.columns:
                total_amounts = self.filtered_results['total_amount'].dropna()
                if len(total_amounts) > 0:
                    report += f"### äº¤æ˜“é‡‘é¢åˆ†æ\n"
                    report += f"- å¹³å‡äº¤æ˜“é‡‘é¢: {total_amounts.mean():.1f} ä¸‡å…ƒ\n"
                    report += f"- æœ€å¤§äº¤æ˜“é‡‘é¢: {total_amounts.max():.1f} ä¸‡å…ƒ\n"
                    report += f"- äº¤æ˜“é‡‘é¢ä¸­ä½æ•°: {total_amounts.median():.1f} ä¸‡å…ƒ\n\n"
            
            # ç¯è·¯ç±»å‹åˆ†æ
            if 'type' in self.filtered_results.columns:
                type_counts = self.filtered_results['type'].value_counts()
                report += f"### ç¯è·¯ç±»å‹åˆ†å¸ƒ\n"
                for loop_type, count in type_counts.items():
                    report += f"- {loop_type}: {count} ä¸ª ({count/len(self.filtered_results)*100:.1f}%)\n"
                report += "\n"
        
        # é«˜é£é™©ç¯è·¯åˆ—è¡¨ï¼ˆå‰10ä¸ªï¼‰
        report += "## é«˜é£é™©ç¯è·¯åˆ—è¡¨ (Top 10)\n\n"
        
        top_loops = self.filtered_results.head(10)
        for i, (_, row) in enumerate(top_loops.iterrows()):
            report += f"### {i+1}. ç¯è·¯ID: {int(row['loop_id'])}\n"
            report += f"- ç±»å‹: {row['type']}\n"
            report += f"- èŠ‚ç‚¹æ•°: {int(row['node_count'])}\n"
            if 'total_amount' in row:
                report += f"- æ€»äº¤æ˜“é‡‘é¢: {row['total_amount']:.1f} ä¸‡å…ƒ\n"
            if 'time_gap_days' in row:
                report += f"- äº¤æ˜“æ—¶é—´é—´éš”: {row['time_gap_days']} å¤©\n"
            if 'equity_concentration' in row:
                report += f"- è‚¡æƒé›†ä¸­åº¦: {row['equity_concentration']:.3f}\n"
            report += f"- ç¯è·¯è·¯å¾„: {row['content'][:100]}...\n\n"
        
        return report
    
    def log(self, message):
        """æ·»åŠ æ—¥å¿—æ¶ˆæ¯"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_message = f"[{timestamp}] {message}\n"
        
        self.log_text.insert(tk.END, log_message)
        self.log_text.see(tk.END)
        
        # æ›´æ–°çŠ¶æ€æ 
        self.status_var.set(message)


def main():
    """ä¸»å‡½æ•°"""
    root = tk.Tk()
    app = AdvancedLoopFilterGUI(root)
    
    # è®¾ç½®çª—å£æ ·å¼
    try:
        root.iconbitmap('icon.ico')
    except:
        pass
    
    root.minsize(1400, 900)
    
    # å¯åŠ¨ä¸»å¾ªç¯
    root.mainloop()


if __name__ == "__main__":
    # æ£€æŸ¥ä¾èµ–
    try:
        import tkinter
        import matplotlib
        import pandas
        import numpy
        import networkx
    except ImportError as e:
        print(f"ç¼ºå°‘ä¾èµ–åº“: {e}")
        print("è¯·å®‰è£…: pip install matplotlib pandas numpy networkx")
        exit(1)
    
    print("ğŸš€ å¯åŠ¨ç‰©äº§ä¸­å¤§å›¾é£æ§ç³»ç»Ÿ - é«˜çº§é—­ç¯ä¼˜ç­›ç³»ç»Ÿ v2.0")
    print("=" * 60)
    print("æ–°åŠŸèƒ½:")
    print("âœ… æ—¶é—´ç»´åº¦åˆ†æ - ä¸Šä¸‹æ¸¸äº¤æ˜“æ—¶é—´é—´éš”æ§åˆ¶")
    print("âœ… è‚¡æƒåˆ†æé›†æˆ - è‡ªåŠ¨è°ƒç”¨åˆ†æè„šæœ¬")
    print("âœ… å®Œæ•´æ€§æ£€æŸ¥ - ç¡®ä¿æ•°æ®å®Œæ•´æ€§")
    print("âœ… è‡ªåŠ¨æ•°æ®è¯»å– - æ™ºèƒ½å‘ç°å¹¶åŠ è½½æ•°æ®")
    print("âœ… çœŸå®æ•°æ®å¯¼å‘ - ä¸ä½¿ç”¨ä¼°ç®—å€¼")
    print("âœ… ç¯è·¯ç±»å‹æ§åˆ¶ - å¯é€‰æ‹©ç‰¹å®šç±»å‹")
    print("=" * 60)
    
    main()