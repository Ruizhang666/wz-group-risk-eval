#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒ–å·¥å›¾é£æ§ç³»ç»Ÿ - ç»¼åˆå»ºæ¨¡è„šæœ¬
ä¸€é”®è¿è¡Œå®Œæ•´çš„å¼‚å¸¸æ£€æµ‹æµç¨‹ï¼šç‰¹å¾å·¥ç¨‹ â†’ æ¨¡å‹è®­ç»ƒ â†’ é›†æˆä¼˜åŒ– â†’ ç»“æœè§£é‡Š

åŠŸèƒ½æµç¨‹ï¼š
1. æ¸…ç†å†å²è¾“å‡ºç›®å½•
2. ç‰¹å¾å·¥ç¨‹ - æå–å’Œæ„å»ºå·¥ç¨‹ç‰¹å¾
3. æ¨¡å‹è®­ç»ƒ - è®­ç»ƒå¤šç§å¼‚å¸¸æ£€æµ‹æ¨¡å‹
4. é›†æˆä¼˜åŒ– - æ™ºèƒ½é›†æˆå¤šæ¨¡å‹ç»“æœ
5. ç»“æœè§£é‡Š - ç”Ÿæˆå¯è§£é‡Šæ€§åˆ†ææŠ¥å‘Š

ç‰ˆæœ¬: v1.0 - ç»¼åˆå»ºæ¨¡è„šæœ¬
ä½œè€…: AIåŠ©æ‰‹
"""

import os
import sys
import time
import shutil
import logging
from pathlib import Path
import warnings

# è®¾ç½®NumExprçº¿ç¨‹æ•°ï¼Œé¿å…è­¦å‘Š
os.environ['NUMEXPR_MAX_THREADS'] = '14'

# æ·»åŠ modelingç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append('modeling')

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def clear_output_directory():
    """æ¸…ç†è¾“å‡ºç›®å½•"""
    output_dir = Path('outputs/anomaly_detection')
    
    if output_dir.exists():
        logger.info("æ¸…ç†å†å²è¾“å‡ºç›®å½•...")
        try:
            shutil.rmtree(output_dir)
            logger.info("âœ… è¾“å‡ºç›®å½•æ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.warning(f"æ¸…ç†ç›®å½•æ—¶å‡ºç°è­¦å‘Š: {e}")
    
    # é‡æ–°åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„
    subdirs = [
        'features', 'models', 'ensemble', 'explanations', 
        'visualizations', 'reports', 'logs'
    ]
    
    for subdir in subdirs:
        (output_dir / subdir).mkdir(parents=True, exist_ok=True)
    
    logger.info("âœ… è¾“å‡ºç›®å½•ç»“æ„é‡å»ºå®Œæˆ")

def run_feature_engineering():
    """è¿è¡Œç‰¹å¾å·¥ç¨‹"""
    logger.info("=" * 70)
    logger.info("æ­¥éª¤ 1/4: ç‰¹å¾å·¥ç¨‹")
    logger.info("=" * 70)
    
    try:
        # å¯¼å…¥ç‰¹å¾å·¥ç¨‹æ¨¡å—
        from feature_engineering import FeatureEngineer
        
        # åˆå§‹åŒ–ç‰¹å¾å·¥ç¨‹å™¨ï¼ˆä½¿ç”¨é»˜è®¤è¾“å…¥æ–‡ä»¶ï¼‰
        engineer = FeatureEngineer()
        
        # è¿è¡Œç‰¹å¾å·¥ç¨‹
        result = engineer.run_feature_engineering()
        
        if result is not None:
            logger.info("âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ")
            return True
        else:
            logger.error("âŒ ç‰¹å¾å·¥ç¨‹å¤±è´¥")
            return False
            
    except ImportError as e:
        logger.error(f"âŒ å¯¼å…¥ç‰¹å¾å·¥ç¨‹æ¨¡å—å¤±è´¥: {e}")
        return False
    except Exception as e:
        logger.error(f"âŒ ç‰¹å¾å·¥ç¨‹æ‰§è¡Œå¤±è´¥: {e}")
        return False

def run_anomaly_detection():
    """è¿è¡Œå¼‚å¸¸æ£€æµ‹æ¨¡å‹è®­ç»ƒ"""
    logger.info("=" * 70)
    logger.info("æ­¥éª¤ 2/4: å¼‚å¸¸æ£€æµ‹æ¨¡å‹è®­ç»ƒ")
    logger.info("=" * 70)
    
    try:
        # å¯¼å…¥å¼‚å¸¸æ£€æµ‹æ¨¡å—
        from optimized_anomaly_detection import OptimizedAnomalyDetection
        
        # åˆå§‹åŒ–å¼‚å¸¸æ£€æµ‹å™¨
        detector = OptimizedAnomalyDetection()
        
        # è¿è¡Œå¼‚å¸¸æ£€æµ‹
        success = detector.run_complete_pipeline()
        
        if success:
            logger.info("âœ… å¼‚å¸¸æ£€æµ‹æ¨¡å‹è®­ç»ƒå®Œæˆ")
            return True
        else:
            logger.error("âŒ å¼‚å¸¸æ£€æµ‹æ¨¡å‹è®­ç»ƒå¤±è´¥")
            return False
            
    except ImportError as e:
        logger.error(f"âŒ å¯¼å…¥å¼‚å¸¸æ£€æµ‹æ¨¡å—å¤±è´¥: {e}")
        return False
    except Exception as e:
        logger.error(f"âŒ å¼‚å¸¸æ£€æµ‹æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
        return False

def run_ensemble_integration():
    """è¿è¡Œé›†æˆä¼˜åŒ–"""
    logger.info("=" * 70)
    logger.info("æ­¥éª¤ 3/4: é›†æˆä¼˜åŒ–")
    logger.info("=" * 70)
    
    try:
        # å¯¼å…¥é›†æˆæ¨¡å—
        from optimized_ensemble_integration import OptimizedEnsembleIntegrator
        
        # æ£€æŸ¥æ¨¡å‹åˆ†æ•°æ–‡ä»¶
        model_scores_file = 'outputs/anomaly_detection/optimized_model_scores.csv'
        if not Path(model_scores_file).exists():
            model_scores_file = 'outputs/anomaly_detection/model_scores.csv'
            if not Path(model_scores_file).exists():
                logger.error("âŒ æ‰¾ä¸åˆ°æ¨¡å‹åˆ†æ•°æ–‡ä»¶")
                return False
        
        # åˆå§‹åŒ–é›†æˆå™¨
        integrator = OptimizedEnsembleIntegrator(
            model_scores_file=model_scores_file,
            n_jobs=-1,
            optimization_trials=50
        )
        
        # è¿è¡Œé›†æˆä¼˜åŒ–
        results = integrator.run_optimized_ensemble()
        
        if results:
            # ä¸ºè§£é‡Šç³»ç»Ÿåˆ›å»ºå…¼å®¹çš„æ–‡ä»¶å
            optimized_results_file = 'outputs/anomaly_detection/ensemble/optimized_final_results.csv'
            explanation_results_file = 'outputs/anomaly_detection/ensemble/final_anomaly_results.csv'
            
            if Path(optimized_results_file).exists():
                import shutil
                shutil.copy2(optimized_results_file, explanation_results_file)
                logger.info("âœ… å·²ä¸ºè§£é‡Šç³»ç»Ÿåˆ›å»ºå…¼å®¹æ–‡ä»¶")
            
            logger.info("âœ… é›†æˆä¼˜åŒ–å®Œæˆ")
            return True
        else:
            logger.error("âŒ é›†æˆä¼˜åŒ–å¤±è´¥")
            return False
            
    except ImportError as e:
        logger.error(f"âŒ å¯¼å…¥é›†æˆæ¨¡å—å¤±è´¥: {e}")
        return False
    except Exception as e:
        logger.error(f"âŒ é›†æˆä¼˜åŒ–æ‰§è¡Œå¤±è´¥: {e}")
        return False

def run_explanation_system():
    """è¿è¡Œè§£é‡Šç³»ç»Ÿ"""
    logger.info("=" * 70)
    logger.info("æ­¥éª¤ 4/4: ç»“æœè§£é‡Šåˆ†æ")
    logger.info("=" * 70)
    
    try:
        # å¯¼å…¥ç®€åŒ–è§£é‡Šç³»ç»Ÿæ¨¡å—
        from anomaly_explanation_system_clean import SimpleAnomalyExplainer
        
        # åˆå§‹åŒ–è§£é‡Šç³»ç»Ÿ
        explainer = SimpleAnomalyExplainer()
        
        # è¿è¡Œè§£é‡Šåˆ†æ
        success = explainer.run_complete_explanation()
        
        if success:
            logger.info("âœ… ç»“æœè§£é‡Šåˆ†æå®Œæˆ")
            return True
        else:
            logger.error("âŒ ç»“æœè§£é‡Šåˆ†æå¤±è´¥")
            return False
            
    except ImportError as e:
        logger.error(f"âŒ å¯¼å…¥è§£é‡Šç³»ç»Ÿæ¨¡å—å¤±è´¥: {e}")
        return False
    except Exception as e:
        logger.error(f"âŒ ç»“æœè§£é‡Šåˆ†æå¤±è´¥: {e}")
        return False

def check_prerequisites():
    """æ£€æŸ¥å‰ç½®æ¡ä»¶"""
    logger.info("æ£€æŸ¥å‰ç½®æ¡ä»¶...")
    
    # æ£€æŸ¥modelingç›®å½•
    modeling_dir = Path('modeling')
    if not modeling_dir.exists():
        logger.error("âŒ æ‰¾ä¸åˆ°modelingç›®å½•")
        return False
    
    # æ£€æŸ¥å¿…éœ€çš„æ¨¡å—æ–‡ä»¶
    required_modules = [
        'modeling/feature_engineering.py',
        'modeling/optimized_anomaly_detection.py',
        'modeling/optimized_ensemble_integration.py',
        'modeling/anomaly_explanation_system_clean.py'
    ]
    
    missing_modules = []
    for module_path in required_modules:
        if not Path(module_path).exists():
            missing_modules.append(module_path)
    
    if missing_modules:
        logger.error("âŒ ç¼ºå°‘å¿…éœ€çš„æ¨¡å—æ–‡ä»¶:")
        for module_path in missing_modules:
            logger.error(f"   - {module_path}")
        return False
    
    logger.info("âœ… æ‰€æœ‰å¿…éœ€çš„æ¨¡å—æ–‡ä»¶éƒ½å­˜åœ¨")
    logger.info("âœ… å‰ç½®æ¡ä»¶æ£€æŸ¥é€šè¿‡")
    return True

def generate_final_summary():
    """ç”Ÿæˆæœ€ç»ˆæ€»ç»“æŠ¥å‘Š"""
    logger.info("ç”Ÿæˆæœ€ç»ˆæ€»ç»“æŠ¥å‘Š...")
    
    try:
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
        output_files = {
            'ç‰¹å¾æ•°æ®': 'outputs/anomaly_detection/features/engineered_features.csv',
            'æ¨¡å‹åˆ†æ•°': 'outputs/anomaly_detection/optimized_model_scores.csv',
            'æœ€ç»ˆç»“æœ': 'outputs/anomaly_detection/ensemble/optimized_final_results.csv',
            'è§£é‡Šç³»ç»Ÿç»“æœ': 'outputs/anomaly_detection/ensemble/final_anomaly_results.csv',
            'ç»¼åˆè§£é‡ŠæŠ¥å‘Š': 'outputs/anomaly_detection/reports/comprehensive_explanation_report.json',
            'HTMLæŠ¥å‘Š': 'outputs/anomaly_detection/reports/explanation_report.html'
        }
        
        logger.info("\n" + "=" * 70)
        logger.info("ğŸ‰ åŒ–å·¥å›¾é£æ§ç³»ç»Ÿå¼‚å¸¸æ£€æµ‹å»ºæ¨¡å®Œæˆï¼")
        logger.info("=" * 70)
        
        logger.info("ğŸ“Š ç”Ÿæˆçš„ä¸»è¦è¾“å‡ºæ–‡ä»¶:")
        for desc, filepath in output_files.items():
            if Path(filepath).exists():
                file_size = Path(filepath).stat().st_size / (1024 * 1024)  # MB
                logger.info(f"   âœ… {desc}: {filepath} ({file_size:.1f}MB)")
            else:
                logger.info(f"   âŒ {desc}: {filepath} (æœªç”Ÿæˆ)")
        
        logger.info("\nğŸ“ å®Œæ•´è¾“å‡ºç›®å½•ç»“æ„:")
        output_dir = Path('outputs/anomaly_detection')
        for subdir in ['features', 'models', 'ensemble', 'explanations', 'visualizations', 'reports']:
            subdir_path = output_dir / subdir
            if subdir_path.exists():
                file_count = len(list(subdir_path.glob('*')))
                logger.info(f"   ğŸ“‚ {subdir}/  ({file_count} ä¸ªæ–‡ä»¶)")
        
        # è¯»å–é£é™©ç»Ÿè®¡
        try:
            import pandas as pd
            final_results = pd.read_csv('outputs/anomaly_detection/ensemble/optimized_final_results.csv')
            risk_distribution = final_results['anomaly_level'].value_counts()
            
            logger.info("\nğŸš¨ é£é™©ç­‰çº§ç»Ÿè®¡:")
            for level, count in risk_distribution.items():
                percentage = count / len(final_results) * 100
                logger.info(f"   {level}: {count} ä¸ªç¯è·¯ ({percentage:.1f}%)")
                
        except Exception as e:
            logger.warning(f"æ— æ³•è¯»å–é£é™©ç»Ÿè®¡: {e}")
        
        logger.info("\nğŸ” æ¨èåç»­æ­¥éª¤:")
        logger.info("   1. æŸ¥çœ‹ explanation_report.html è·å–ç›´è§‚çš„åˆ†æç»“æœ")
        logger.info("   2. æ£€æŸ¥ optimized_final_results.csv ä¸­çš„é«˜é£é™©ç¯è·¯")
        logger.info("   3. æ ¹æ®è§£é‡ŠæŠ¥å‘Šåˆ¶å®šé£é™©ç¼“è§£ç­–ç•¥")
        logger.info("   4. å»ºç«‹æŒç»­ç›‘æ§æœºåˆ¶")
        
        logger.info("=" * 70)
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ€»ç»“æŠ¥å‘Šæ—¶å‡ºç°é”™è¯¯: {e}")

def main():
    """ä¸»å‡½æ•° - è¿è¡Œå®Œæ•´çš„å»ºæ¨¡æµç¨‹"""
    print("=" * 80)
    print("ğŸ­ åŒ–å·¥å›¾é£æ§ç³»ç»Ÿ - ç»¼åˆå»ºæ¨¡è„šæœ¬")
    print("ğŸš€ ä¸€é”®è¿è¡Œå®Œæ•´å¼‚å¸¸æ£€æµ‹æµç¨‹")
    print("=" * 80)
    
    start_time = time.time()
    
    # æ£€æŸ¥å‰ç½®æ¡ä»¶
    if not check_prerequisites():
        logger.error("å‰ç½®æ¡ä»¶æ£€æŸ¥å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æ‰§è¡Œ")
        
        # æä¾›å¸®åŠ©ä¿¡æ¯
        print("\n" + "=" * 60)
        print("ğŸ“‹ ä½¿ç”¨è¯´æ˜:")
        print("=" * 60)
        print("æ­¤è„šæœ¬éœ€è¦ä»¥ä¸‹æ•°æ®æ–‡ä»¶æ‰èƒ½è¿è¡Œ:")
        print("1. ç¯è·¯æ•°æ®æ–‡ä»¶ (loops_data.csv)")
        print("2. èŠ‚ç‚¹æ•°æ®æ–‡ä»¶ (nodes_data.csv)")
        print("3. è¾¹æ•°æ®æ–‡ä»¶ (edges_data.csv)")
        print("\nğŸ’¡ å¦‚æœæ‚¨æœ‰å…¶ä»–æ ¼å¼çš„æ•°æ®æ–‡ä»¶ï¼Œè¯·ï¼š")
        print("1. å°†æ•°æ®æ–‡ä»¶é‡å‘½åæˆ–å¤åˆ¶åˆ° data/ ç›®å½•")
        print("2. ç¡®ä¿æ–‡ä»¶æ ¼å¼ä¸º CSV")
        print("3. æˆ–è€…å…ˆè¿è¡Œæ•°æ®é¢„å¤„ç†è„šæœ¬")
        print("\nğŸ“ å½“å‰æ£€æµ‹åˆ°çš„æ–‡ä»¶:")
        data_dir = Path('data')
        if data_dir.exists():
            for file in data_dir.glob('*.csv'):
                file_size = file.stat().st_size / (1024 * 1024)
                print(f"   - {file.name} ({file_size:.1f}MB)")
        print("=" * 60)
        return
    
    # è¯¢é—®ç”¨æˆ·æ˜¯å¦æ¸…ç†è¾“å‡ºç›®å½•
    response = input("\næ˜¯å¦æ¸…ç†å†å²è¾“å‡ºç›®å½•ï¼Ÿ(y/n, é»˜è®¤y): ").strip().lower()
    if response in ['', 'y', 'yes']:
        clear_output_directory()
    
    # æ‰§è¡Œå››ä¸ªæ­¥éª¤
    steps = [
        ("ç‰¹å¾å·¥ç¨‹", run_feature_engineering),
        ("å¼‚å¸¸æ£€æµ‹æ¨¡å‹è®­ç»ƒ", run_anomaly_detection), 
        ("é›†æˆä¼˜åŒ–", run_ensemble_integration),
        ("ç»“æœè§£é‡Šåˆ†æ", run_explanation_system)
    ]
    
    success_count = 0
    
    for step_name, step_func in steps:
        try:
            if step_func():
                success_count += 1
                logger.info(f"âœ… {step_name} æˆåŠŸå®Œæˆ")
            else:
                logger.error(f"âŒ {step_name} æ‰§è¡Œå¤±è´¥")
                break
                
        except KeyboardInterrupt:
            logger.warning("ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
            break
        except Exception as e:
            logger.error(f"âŒ {step_name} æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
            break
    
    # è®¡ç®—æ€»è€—æ—¶
    total_time = time.time() - start_time
    
    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    if success_count == len(steps):
        generate_final_summary()
        logger.info(f"\nğŸ¯ å…¨éƒ¨ {len(steps)} ä¸ªæ­¥éª¤æˆåŠŸå®Œæˆï¼æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
    else:
        logger.error(f"\nğŸ’¥ åªå®Œæˆäº† {success_count}/{len(steps)} ä¸ªæ­¥éª¤ï¼Œæ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
        logger.error("è¯·æ£€æŸ¥æ—¥å¿—ä¿¡æ¯å¹¶è§£å†³é—®é¢˜åé‡æ–°è¿è¡Œ")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œï¼Œç¨‹åºé€€å‡º")
    except Exception as e:
        print(f"\nğŸ’¥ ç¨‹åºæ‰§è¡Œå‡ºç°å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc() 